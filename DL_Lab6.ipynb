{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhask94/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "## Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "## There are two parts of this lab:\n",
        "###  1.   Wiring up a basic sequence-to-sequence computation graph\n",
        "###  2.   Implementing your own GRU cell.\n",
        "\n",
        "\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l7bdZWxvJrsx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "0ec6fb43-ce52-4fa1-8d8e-df573a31e7d9"
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "from IPython.core.debugger import set_trace\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "while file.count('\\n\\n') > 0: # get rid of newline characters\n",
        "  file = file.replace('\\n\\n', '\\n')\n",
        "file = file.replace('\\n', ' ')\n",
        "file = file.replace('  ', ' ')\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-19 21:13:50--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 52.45.119.166, 3.214.17.10, 52.2.48.133, ...\n",
            "Connecting to piazza.com (piazza.com)|52.45.119.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2019-10-19 21:13:51--  https://d1b10bmlvqabco.cloudfront.net/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)... 99.86.32.60, 99.86.32.164, 99.86.32.66, ...\n",
            "Connecting to d1b10bmlvqabco.cloudfront.net (d1b10bmlvqabco.cloudfront.net)|99.86.32.60|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "\r./text_files.tar.gz   0%[                    ]       0  --.-KB/s               \r./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-10-19 21:13:51 (34.1 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "file_len = 2526054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTIgx4SIKQ9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a37b8bd7-7471-4f0e-da49-2a7039177777"
      },
      "source": [
        "import glob\n",
        "print(glob.glob(\"./text_files/*.txt\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./text_files/tiny_shakespeare.txt', './text_files/abcd.txt', './text_files/abab.txt', './text_files/alma.txt', './text_files/test1.txt', './text_files/lotr.txt', './text_files/switch.bat.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TxBeKeNjJ0NQ",
        "outputId": "3e1368bb-19c5-4c7d-ac66-8d7f67e2457e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en another clear voice, as young and as ancient as Spring, like the song of a glad water flowing down into the night from a bright morning in the hills, came falling like silver to meet them: Now let t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "On0_WitWJ99e",
        "outputId": "ae76b301-fe2f-46f0-88ed-a7c0ce21c8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Create a custom GRU cell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aavAv50ZKQ-F",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = num_layers\n",
        "    \n",
        "#     self.w_ir = []\n",
        "#     self.w_hr = []\n",
        "#     self.w_iz = []\n",
        "#     self.w_hz = []\n",
        "#     self.w_in = []\n",
        "#     self.w_hn = []\n",
        "    \n",
        "#     for l in range(self.n_layers):\n",
        "#       self.w_ir.append(nn.Linear(input_size,  hidden_size))\n",
        "#       self.w_hr.append(nn.Linear(hidden_size, hidden_size))\n",
        "#       self.w_iz.append(nn.Linear(input_size,  hidden_size))\n",
        "#       self.w_hz.append(nn.Linear(hidden_size, hidden_size))\n",
        "#       self.w_in.append(nn.Linear(input_size,  hidden_size))\n",
        "#       self.w_hn.append(nn.Linear(hidden_size, hidden_size))\n",
        "\n",
        "    self.w_ir = nn.Linear(input_size,  hidden_size)\n",
        "    self.w_hr = nn.Linear(hidden_size, hidden_size)\n",
        "    self.w_iz = nn.Linear(input_size,  hidden_size)\n",
        "    self.w_hz = nn.Linear(hidden_size, hidden_size)\n",
        "    self.w_in = nn.Linear(input_size,  hidden_size)\n",
        "    self.w_hn = nn.Linear(hidden_size, hidden_size)\n",
        "    \n",
        "    self.sig = nn.Sigmoid()\n",
        "    self.tan = nn.Tanh()    \n",
        "    \n",
        "  def forward(self, inputs, prev_hidden):\n",
        "#     hidden = torch.empty(prev_hidden.shape)\n",
        "\n",
        "#     for l in range(self.n_layers):\n",
        "    r_t = self.sig(self.w_ir(inputs) + self.w_hr(prev_hidden))\n",
        "    z_t = self.sig(self.w_iz(inputs) + self.w_hz(prev_hidden))\n",
        "    n_t = self.tan(self.w_in(inputs) + r_t*self.w_hn(prev_hidden))\n",
        "    hidden = (1 - z_t) * n_t + z_t * prev_hidden\n",
        "    output = hidden[-1:]\n",
        "    \n",
        "    return output, hidden\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Create an RNN class that extends from nn.Module.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d6tNdEnzWj5F",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "    # inputs are embedded to be hidden_size\n",
        "    self.gru = GRU(input_size=hidden_size, hidden_size=hidden_size, \n",
        "                      num_layers=n_layers)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.decode = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    embed = self.embedding(input_char).view(1,1,-1)\n",
        "    output, hidden = self.gru(embed, hidden)\n",
        "    output = self.relu(self.decode(output))\n",
        "    \n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.n_layers, 1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrhXghEPKD-5",
        "colab": {}
      },
      "source": [
        "def random_training_set():    \n",
        "  chunk = random_chunk()\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Fill in the pieces.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ALC3Pf8Kbsi",
        "colab": {}
      },
      "source": [
        "def train(input_str, target_str):\n",
        "  decoder_optimizer.zero_grad()\n",
        "  hidden = decoder.init_hidden()\n",
        "  loss = 0\n",
        "  \n",
        "  for in_char, target_char in zip(input_str, target_str):\n",
        "    \n",
        "    char_hat, hidden = decoder(in_char, hidden)\n",
        "    target_char = target_char.unsqueeze(0)\n",
        "    loss += criterion(char_hat.squeeze(0), target_char)\n",
        "    \n",
        "  loss.backward()\n",
        "  decoder_optimizer.step()\n",
        "  \n",
        "  return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Fill out the evaluate function to generate text frome a primed string\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B-bp-OZ1KjNh",
        "colab": {}
      },
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.6):\n",
        "  with torch.no_grad():\n",
        "    hidden = decoder.init_hidden()\n",
        "    prediction = prime_str + '' # copies prime_str values, not a ptr\n",
        "    primer_input = char_tensor(prime_str)\n",
        "    all_chars = string.printable \n",
        "    \n",
        "    for char in primer_input[:-1]:\n",
        "      _, hidden = decoder(char, hidden)\n",
        "    \n",
        "    in_char = primer_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "      pred, hidden = decoder(in_char, hidden)\n",
        "      pred_dist = F.softmax(pred.squeeze(0) / temperature, dim=1)\n",
        "      top_idx = torch.multinomial(pred_dist, 1)[0]\n",
        "      \n",
        "      char_decoded = all_chars[top_idx]\n",
        "      in_char = char_tensor(char_decoded)\n",
        "      prediction += char_decoded\n",
        "      \n",
        "  return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs gave.\n",
        "\n",
        "**TODO:** \n",
        "\n",
        "**DONE:**\n",
        "* Create some cool output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-nXFeCmdKodw",
        "colab": {}
      },
      "source": [
        "import time\n",
        "n_epochs = 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 3\n",
        "lr = 0.001\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xKfozqw-6eqb",
        "outputId": "33da7f89-a17c-4f46-fe7e-1ccc35996866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "    print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "    print(evaluate('Wh', predict_len=100, temperature=0.6), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "    all_losses.append(loss_avg / plot_every)\n",
        "    loss_avg = 0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.43207693099975586 (0 0%) 921.3820]\n",
            "Wh)f[`[LO}ppZ.;HX+S55tsO-4)g/?s<AAwybZ\u000bAe&1d\u000b{;\u000bLC\rxohE&L#!03H:Zu5A0B9U?KM\f\"1'$.*P[?*\fy'<\fMO4s9pug01,> \n",
            "\n",
            "[78.68216896057129 (200 4%) 435.5261]\n",
            "Whe head to the the thing the the hastint has skinged and the and to the niling the and wat siasA haro \n",
            "\n",
            "[156.43271708488464 (400 8%) 435.5623]\n",
            "Whe and the the are and canstere wore the where and saind the cand. go and cound the kne wather it sai \n",
            "\n",
            "[235.2494945526123 (600 12%) 406.8815]\n",
            "What the lound the stong a down the the it in as at his and that hoult and the do the lonting that wen \n",
            "\n",
            "[314.0422761440277 (800 16%) 350.5024]\n",
            "Whe ~or the long great befreed the dold have sing was and to the were the was to the worder hould they \n",
            "\n",
            "[392.540890455246 (1000 20%) 460.0086]\n",
            "Whord. 'Where the greather the bown be canter now a dow do said dooked were of coald said not of the r \n",
            "\n",
            "[470.6464116573334 (1200 24%) 330.0115]\n",
            "Wh the ride not to the many a the chalking and the greet a long the great he courtherned drouss to the \n",
            "\n",
            "[549.4033305644989 (1400 28%) 346.7403]\n",
            "When his becaust long and about and deal some and the lose in the way a say of the mound a long of the \n",
            "\n",
            "[627.3715200424194 (1600 32%) 338.3292]\n",
            "Whing and they were the was sore on the lare in and said Aragorm the days on the deads of the lead rem \n",
            "\n",
            "[705.8590536117554 (1800 36%) 359.6662]\n",
            "Wher his earsten in the deep howed the long and be had bent and would had bear the will be to good wer \n",
            "\n",
            "[784.5223269462585 (2000 40%) 315.3227]\n",
            "Whis mastally will shister your it was its an the cund the south are at he seen dark before the sound  \n",
            "\n",
            "[863.1632356643677 (2200 44%) 310.5831]\n",
            "Wht and were his eyes. ' he said. 'What have gret what had recrows dister the hobbits of the tong and  \n",
            "\n",
            "[941.0375044345856 (2400 48%) 346.3803]\n",
            "Whing it one on the pass had a leat of the very fear of the with was a grow on time to not was some ro \n",
            "\n",
            "[1019.4295451641083 (2600 52%) 297.6752]\n",
            "Whurre for you have had and shall very many and of the will before the filled and then he was stepped  \n",
            "\n",
            "[1097.1857070922852 (2800 56%) 303.3744]\n",
            "Whe said. 'So the forgotten from the end it is the torthing a stones of the ride the gried flace no be \n",
            "\n",
            "[1175.2767777442932 (3000 60%) 332.1362]\n",
            "Wht of should the news were the words. I have the brand of the even and could was the bring of the bre \n",
            "\n",
            "[1253.0356094837189 (3200 64%) 322.3629]\n",
            "Whree in the door and the days. but from he said the {ound was aland, and a land in the dark the black \n",
            "\n",
            "[1331.2901358604431 (3400 68%) 344.5120]\n",
            "Where is in his glear and closes, and the move the sure the dark to the stones. I may blast on the sou \n",
            "\n",
            "[1409.6878504753113 (3600 72%) 340.7249]\n",
            "Whey swords the worth they had and more now of a string was now would be door. 'garden before the stay \n",
            "\n",
            "[1488.100013256073 (3800 76%) 346.7693]\n",
            "When the said them for the wind. I not know his sudden and were being all down to do his reat and beho \n",
            "\n",
            "[1566.0375900268555 (4000 80%) 290.7711]\n",
            "Where were least to my closes. 'All the same in the making of the hight and was a sturing in a house i \n",
            "\n",
            "[1644.2362251281738 (4200 84%) 271.1827]\n",
            "Where in the staid first swiftly can the ball the small that he countaining still he was for get fear  \n",
            "\n",
            "[1722.5067296028137 (4400 88%) 295.1929]\n",
            "i \n",
            "\n",
            "[1801.0676996707916 (4600 92%) 320.6919]\n",
            "Whill the feet to they coming the door climbed. 'It make the still the mountain so the recout to the l \n",
            "\n",
            "[1878.9033086299896 (4800 96%) 308.3461]\n",
            "Where he with there was and in the hold to know and come were good to a before the strong to faller. ' \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEuBCF1V9LlG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "2bc6e7f2-5562-4091-cf16-7c16d6644cf7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(range(len(all_losses)), all_losses, label='loss')\n",
        "plt.xlabel('Epoch / {}'.format(plot_every))\n",
        "_ = plt.ylabel('Loss')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsrV/wNHW0lrv6c1TAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ee0so6aKJ5L8",
        "outputId": "25f8c602-2ded-467b-b855-52ee52825a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "  print(evaluate(start_strings[start], 200, temperature=0.58), '\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " he\n",
            " he was a stark that in the earth and a cliff fall of the failing the name he had all the sandil their had behind her and flew speak you know, them , failings and that in the thing son and then the say,  \n",
            "\n",
            " ra\n",
            " ran here and companions a pressed and lay in the old dark some things that the keeping in the mount of the old the hobbits as the hobbitswered the passing the glanned in the house and strent about the s \n",
            "\n",
            " wh\n",
            " what they seemed the end in the hobbits be shadows of the mind, and the more, so fell in the graves and leet was said on the great in silendand fell, and even a like the shadow. I feared at in the stone \n",
            "\n",
            " ra\n",
            " ran and their faces and dark death the stood things that he leave from the Warl! We had they had though them to shadows of the hissed his far black of speed. I will silend of the dark as he seemed then  \n",
            "\n",
            " wh\n",
            " what the feet the tide the hobbits still though a great great withranding the shadows that was any rears of the great mind his friend, as if you secret in his was all the thing they were steps any all t \n",
            "\n",
            " G\n",
            " Gandalf she was and water his eyes that the hissed. I know the laughed and deep with a side, swerth the still shapes had be should think day near slopped the Gondor had been all shall some in the teath \n",
            "\n",
            " lo\n",
            " long he haster my place of the trees of the shadow and cut that is cross the strung the feet master, if there would ever on a short of the enemy still and deady in the still in the red in the valless to \n",
            "\n",
            " wh\n",
            " which all that well, not so the think side more and the eaves a black a strengthed among the shadow with the fellarmed. I shall light of the rest comes, and the early a starget of the stand and turned t \n",
            "\n",
            " I \n",
            " I do be his forming in his had not know their fell him a while with a lart and their capted the shadow closed in the hobbits be much seeking to the stone that was a while side a still be have cliff the  \n",
            "\n",
            " wh\n",
            " while under the should not gone and thing the sloped then were great feet and that the reckoning on the his was really behind the will ran all the hiss and clothout before the others, might for silled o \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDm_lh3TK1rk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "386f7921-8ed5-4ff9-9369-0e7c6e2168f9"
      },
      "source": [
        "file = unidecode.unidecode(open('./text_files/alma.txt').read())\n",
        "while file.count('\\n\\n') > 0: # get rid of newline characters\n",
        "  file = file.replace('\\n\\n', '\\n')\n",
        "file = file.replace('\\n', ' ')\n",
        "file = file.replace('  ', ' ')\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n",
        "\n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "    print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "    print(evaluate('Wh', predict_len=100, temperature=0.6), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "    all_losses.append(loss_avg / plot_every)\n",
        "    loss_avg = 0\n",
        "    "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 462561\n",
            "[0.42401838302612305 (0 0%) 915.5421]\n",
            "sK\n",
            "$flFqTa\n",
            "&2ch)FIwDl+A-pOk! 1W|J \n",
            "\n",
            "[79.2475745677948 (200 4%) 529.9556]\n",
            "Whon dested, and the his theay and to were his ow the lad the ahe brey out the wich had or the the and \n",
            "\n",
            "[157.52569270133972 (400 8%) 351.1539]\n",
            "Whre peall ove wards out the kand the shold, who his he should the and to he same that he pare the war \n",
            "\n",
            "[235.7586543560028 (600 12%) 316.1318]\n",
            "Whour sent, the grether and the repites, and the reathere oprering the came said there in the king the \n",
            "\n",
            "[314.26549220085144 (800 16%) 294.0076]\n",
            "What cause and unto the city by the name to that the pearst the chight not came to their his shall the \n",
            "\n",
            "[392.58536982536316 (1000 20%) 320.8643]\n",
            "Whe pass the lands ok is they was the word on the time to that the land o) repent to desaid upon the w \n",
            "\n",
            "[470.9219169616699 (1200 24%) 293.3231]\n",
            "Whe was they words of the words of the people, and came to them and the word was and the words, behold \n",
            "\n",
            "[548.946722984314 (1400 28%) 325.8024]\n",
            "What we were them the such ever the catted to pass that they were feeth the never the easthone the cit \n",
            "\n",
            "[627.3978035449982 (1600 32%) 236.6616]\n",
            "Whe come to calles of the land of the beat the nemle the contruch the landes because that the great th \n",
            "\n",
            "[705.4134631156921 (1800 36%) 277.3738]\n",
            "What he shall have the words of the came to pass that the cause the cause the land of Christ unto thei \n",
            "\n",
            "[782.9518661499023 (2000 40%) 271.4090]\n",
            "What the man freed unto him and that they did being that they wild be said(ent unto the say conceed an \n",
            "\n",
            "[861.1816966533661 (2200 44%) 233.3500]\n",
            "Why did come up their heade the church came to pass the chie caties unto the bode of his do were and w \n",
            "\n",
            "[939.7524337768555 (2400 48%) 236.8701]\n",
            "Whe were no seeption up of the land of men the was slain of when the land of Ammoni that they were and \n",
            "\n",
            "[1017.4682128429413 (2600 52%) 215.0833]\n",
            "Whe fathers of you they went and repented of the land of Ammonihah did faith ye are nearth of the fast \n",
            "\n",
            "[1095.8731527328491 (2800 56%) 291.2395]\n",
            "What he was in my possess, thou works which was with his people which he would such do it came to pass \n",
            "\n",
            "[1174.1669533252716 (3000 60%) 309.4308]\n",
            "Wh with the land of Ammon to this people of the remiest of the people of the time and sent that the re \n",
            "\n",
            "[1252.3119041919708 (3200 64%) 280.6296]\n",
            "Wherefore, they were did bring and them also men and the name to pass that Ammon and ordain to the peo \n",
            "\n",
            "[1330.4516892433167 (3400 68%) 211.6934]\n",
            "Wher would be desired, and they were forth your speaking to the church, and they were not be would not \n",
            "\n",
            "[1408.4405624866486 (3600 72%) 304.0223]\n",
            "Whey had begin to be in surrection of their seed the people of their city of my servants they would se \n",
            "\n",
            "[1486.530178785324 (3800 76%) 214.8030]\n",
            "Whis they did were of the wilderness of the peace of the prosed a come and prosted unto them# the land \n",
            "\n",
            "[1564.6463119983673 (4000 80%) 192.3257]\n",
            "Wherefore he had should have the toulf, that which was have hearts which is into the things, and the p \n",
            "\n",
            "[1642.655018568039 (4200 84%) 286.8642]\n",
            "Whis harden the people of valled their earthound the city of Ammonihah, and your brethren were people  \n",
            "\n",
            "[1720.8112652301788 (4400 88%) 206.3402]\n",
            "Wh might be the truth of the things which he did hast not come the truth by the set that he could and  \n",
            "\n",
            "[1798.5128169059753 (4600 92%) 178.9247]\n",
            "Wh\fer this therefore they were stronged by this people of Do are things we should be are from this peo \n",
            "\n",
            "[1877.1210763454437 (4800 96%) 247.5945]\n",
            "Wh the river unto us did not be that there was a pass that they took their spirit of even according to \n",
            "\n",
            " pa\n",
            " part of the land which the land of the people of Ammonihah, that they were also destroy their wilderness all many to slain of the armies of his name all the seding to the people of $urch which it came t \n",
            "\n",
            " my\n",
            " my are be bring the people of Moses to the land which was the name of the word we did save their wound, and they had also take and the people of day of the land of Uurchation, that they are teach the pl \n",
            "\n",
            " he\n",
            " he was and his heart of the word were concerning the land of Ammonihah, that the words of the word his destruction, and his words which they had stop of the forth and a see before the wildersh the land  \n",
            "\n",
            " ca\n",
            " cause of the land of (and he did not son, they were not the people of the land of 0one hearts of the borders of the city of Ammon and they were strengthen the true of the land of heart, they had not all \n",
            "\n",
            " he\n",
            " he did come unto you that when the sins of the ware of the sword of Ammon and their words of the land of the land of Ammonihah to the name of the seashored to his should be many to the destrophed in the \n",
            "\n",
            " he\n",
            " he have been under the people of Ammoroni and the way unto the land of Antipus to gold that the way of the land of the land of the first and the forth year of the word of should not forth to the word, i \n",
            "\n",
            " Th\n",
            " The hands of the name were borders of the in the land of unto the words of sparing to the church were strong to the cause of the wilderness their words of the land of Antipus not the land of heard them  \n",
            "\n",
            " ca\n",
            " cause of all the land of Ammonihah were also his said unto the time to the people of the earth, and also reclich the word which they had great were seed on the arrightened that they were not be desire o \n",
            "\n",
            " wh\n",
            " who had been declare to righteousness the land of Ammon, to the land of Ammon, and have been unto the people of For the word, they had been people of the true to the came to pass that they were a many t \n",
            "\n",
            " ca\n",
            " cause, the land to great place of the armies of the land of \\owh were also lay to command thee was an also caused the hands of our brethren which was in the thing to the word round and the land of Antip \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzAoc6QiVBew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(1)\n",
        "plt.plot(range(len(all_losses)), all_losses, label='loss')\n",
        "plt.xlabel('Epoch / {}'.format(plot_every))\n",
        "_ = plt.ylabel('Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2klHBiGTVFB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "32412055-6c92-4860-c1b4-395659a21a61"
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" An \", \" ca\", \" my\", \" pr\", \" pa\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "  print(evaluate(start_strings[start], 200, temperature=0.58), '\\n')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Th\n",
            " The trust of the word which was a should be the people of the word, that he did take with the people of the words of the marchful were strength and the people of Ompering that their slain the was and th \n",
            "\n",
            " he\n",
            " he had from the name of the seashoren of the land of my caused to the word of the land of Alma and their wilderness of their name, that he throwest to destroyed to the son of the 2nd into the people of  \n",
            "\n",
            " my\n",
            " my prison, and they had gathered the land of 3nto the people of his brethren and the land of his heard to his son, they were such appointed with the end their great was must and the seashore to reston t \n",
            "\n",
            " Th\n",
            " The time and his great not be that a stand to the land of the Uram, who were firth of the word, and the seast of the twirt of their fied and the land which the word of Ammon and also their brethren and  \n",
            "\n",
            " he\n",
            " he were aloned to the word of the land of the land of Antions to the land of Even the wilderness which is a great they should be commanded the sword of the land of Antified to the land of Antipus and he \n",
            "\n",
            " pa\n",
            " part of the people of the land with the commanded to be a fallen the armies of the 4on and the time of the land of }urst in all the falles and the land of Ontiful in the word to the land of Ammon, and t \n",
            "\n",
            " Th\n",
            " The fallen to the land of Lamonihah, who were take the land of the land of Ammon, the slain of the word and the people of Ammon had also deptain the land of Ammon and fear to the strength to the sword t \n",
            "\n",
            " ca\n",
            " caused that he began to pass that they were not believe that they were as the people of heard to the seashore had been themness--Ammon, and the land of the did feen should gran and the land of the peopl \n",
            "\n",
            " he\n",
            " he was been to pass that they would are the land of `how, and the reign of the remies of their wilderness which they were also fallen of the hands of the heart of death and the land you that he was to s \n",
            "\n",
            " An \n",
            " An were also part of his brethren and cast to gold unto him to good forth and so sent and the blood of their words as to slain cast the reign of the people of ? of the epossession of the land of men to t \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHYr-sNZSHL7",
        "colab_type": "text"
      },
      "source": [
        "Things the RNN did well:\n",
        "- For the most part, outputs real words\n",
        "- Picked up on names of people and places\n",
        "- Caught onto general style (words like repent, faith, ordain, wilderness, etc.)\n",
        "\n",
        "Things it didn't do so well:\n",
        "- Form coherent senteces\n",
        "- Proper grammer\n",
        "- Used random symbols sometimes (#,%,<, etc.)"
      ]
    }
  ]
}