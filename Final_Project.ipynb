{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpLgBkLMSCk",
        "colab_type": "code",
        "outputId": "7f55f093-84b7-41b9-f820-8e26310ea9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# imports for training data\n",
        "!if ( ! ls . | grep pytransform ); then git clone https://github.com/mhask94/pytransform.git; fi\n",
        "# !git clone https://github.com/mhask94/pytransform.git\n",
        "from pytransform.common import skew\n",
        "from pytransform.quaternion import Quaternion as Quat\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytransform'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 62 (delta 5), reused 11 (delta 5), pack-reused 51\n",
            "Unpacking objects: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFbSU4rzH849",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports for pytorch\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73-GfR1p7usv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes for quadrotor state and dynamics\n",
        "class State():\n",
        "    def __init__(self, arr=np.empty(0)):\n",
        "        if len(arr) == 0:\n",
        "            self.arr = np.zeros((10,1), dtype=np.float64)\n",
        "            self.arr[3] = 1\n",
        "        else:\n",
        "            assert arr.shape == (10, 1)\n",
        "            if not arr.dtype == np.float64:\n",
        "              arr = np.array(arr, dtype=np.float64)\n",
        "            arr.dtype = np.float64\n",
        "            self.arr = arr\n",
        "\n",
        "    def __getitem__(self, position):\n",
        "        return self.arr[position]\n",
        "    def __str__(self):\n",
        "        s = 'p: ' + str(self.p.flatten()) + '\\nq: ' + self.q.__str__() + \\\n",
        "                '\\nv: ' + str(self.v.flatten())\n",
        "        s = s.replace('[ ', '[')\n",
        "        s = s.replace(', ', ' ')\n",
        "        s = s.replace(' ]', ']')\n",
        "        return s\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "    def __add__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        out = np.empty(self.arr.shape)\n",
        "        out[:3]  = self.p + other[:3]\n",
        "        out[3:7] = (self.q + other[3:6]).elements\n",
        "        out[7:]  = self.v + other[6:]\n",
        "        return State(out)\n",
        "    def __iadd__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        self.arr[:3] += other[:3]\n",
        "        self.arr[3:7] = (self.q + other[3:6]).elements\n",
        "        self.arr[7:] += other[6:]\n",
        "        return self\n",
        "    @property\n",
        "    def p(self):\n",
        "        return self.arr[:3]\n",
        "    @property\n",
        "    def q(self):\n",
        "        return Quat(self.arr[3:7])\n",
        "    @property\n",
        "    def v(self):\n",
        "        return self.arr[7:]\n",
        "    @property\n",
        "    def elements(self):\n",
        "        return self.arr.copy()\n",
        "    def copy(self):\n",
        "        return State(self.arr.copy())\n",
        "\n",
        "class Dynamics():\n",
        "    def __init__(self):\n",
        "        self.k1 = np.zeros((9,1))\n",
        "        self.k2 = np.zeros((9,1))\n",
        "        self.k3 = np.zeros((9,1))\n",
        "        self.k4 = np.zeros((9,1))\n",
        "        self.cd = 0.1\n",
        "        e_z = np.array([[0,0,1]]).T\n",
        "        self.g = 9.8065 * e_z\n",
        "        self.se = 0.5\n",
        "\n",
        "    def run(self, xu, dt):\n",
        "        x,u = State(xu[:10]), xu[10:]\n",
        "        self.k1 = self.f(x, u)\n",
        "        self.k2 = self.f(x + self.k1*(dt/2), u)\n",
        "        self.k3 = self.f(x + self.k2*(dt/2), u)\n",
        "        self.k4 = self.f(x + self.k3*dt, u)\n",
        "        x += (self.k1 + 2*(self.k2 + self.k3) + self.k4) * (dt/6)\n",
        "        return x\n",
        "\n",
        "    def f(self, x, u):\n",
        "        s, w = u[0], u[1:]\n",
        "        dx = np.empty(self.k1.shape)\n",
        "        dx[:3] = x.q.rota(x.v)\n",
        "        dx[3:6] = w\n",
        "        dx[6:] = -self.g*(s/self.se) - self.cd*x.v + x.q.rotp(self.g) - \\\n",
        "                skew(w) @ x.v\n",
        "        return dx\n",
        "\n",
        "    @property\n",
        "    def state(self):\n",
        "        return self.x.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oER-ve3bviM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator():\n",
        "  def __init__(self, batch_size=50):\n",
        "    self.batch_size = batch_size\n",
        "    self.pos_lim = 300\n",
        "    self.att_lim = np.pi\n",
        "    self.vel_lim = 10\n",
        "    self.rate_lim = 2*np.pi\n",
        "    self.s_lim = 1\n",
        "    self.dyn = Dynamics()\n",
        "\n",
        "  def getRandomInput(self):\n",
        "    xu = np.empty((14,1))\n",
        "    xu[:2] = np.random.uniform(-self.pos_lim, self.pos_lim, (2,1))\n",
        "    xu[2] = np.random.uniform(-self.pos_lim, 0)\n",
        "    mask = np.random.uniform(size=3) > 0.2\n",
        "    euler = np.random.uniform(-self.att_lim, self.att_lim, 3) * mask\n",
        "    xu[3:7] = Quat.from_euler(*euler).elements\n",
        "    xu[7:10] = np.random.uniform(-self.vel_lim, self.vel_lim, (3,1))\n",
        "    xu[10] = np.random.uniform(0, self.s_lim)\n",
        "    xu[11:] = np.random.uniform(-self.rate_lim, self.rate_lim, (3,1))\n",
        "    return xu\n",
        "\n",
        "  def getBatch(self):\n",
        "    batch_in = np.empty((self.batch_size, 1, 14, 1))\n",
        "    batch_out = np.empty((self.batch_size, 1, 10, 1))\n",
        "    for i in range(self.batch_size):\n",
        "      batch_in[i,0] = self.getRandomInput()\n",
        "      batch_out[i,0] = self.dyn.run(batch_in[i,0], 0.01).elements\n",
        "    return batch_in, batch_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4SMzucDAkn5",
        "colab_type": "code",
        "outputId": "02f56dd7-e689-4aa4-b23b-a3e08ef2163d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def testGen():\n",
        "  data_gen = DataGenerator(batch_size=2)\n",
        "  ran = data_gen.getRandomInput()\n",
        "  print('rand: ', ran)\n",
        "\n",
        "  x, truth = data_gen.getBatch()\n",
        "  print('x: \\n', x)\n",
        "  print('truth: \\n', truth)\n",
        "\n",
        "testGen()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rand:  [[-2.77005722e+02]\n",
            " [-6.25429536e+00]\n",
            " [-2.40041210e+02]\n",
            " [ 3.01457333e-02]\n",
            " [-3.52175583e-01]\n",
            " [ 7.97813085e-02]\n",
            " [ 9.32039986e-01]\n",
            " [-7.02200149e+00]\n",
            " [-7.38796821e+00]\n",
            " [-8.85306413e+00]\n",
            " [ 5.30992424e-01]\n",
            " [-3.51855717e+00]\n",
            " [ 4.37743989e+00]\n",
            " [ 1.47724905e+00]]\n",
            "x: \n",
            " [[[[-4.00206898e+01]\n",
            "   [-2.47253451e+02]\n",
            "   [-1.92222032e+02]\n",
            "   [ 5.41198380e-01]\n",
            "   [-8.40516550e-01]\n",
            "   [ 1.09723358e-03]\n",
            "   [-2.51999578e-02]\n",
            "   [ 3.51785727e+00]\n",
            "   [-1.25172220e+00]\n",
            "   [ 4.47370697e+00]\n",
            "   [ 4.72194621e-01]\n",
            "   [ 2.89448780e+00]\n",
            "   [ 4.39333388e+00]\n",
            "   [-2.48102119e+00]]]\n",
            "\n",
            "\n",
            " [[[-6.75265329e+01]\n",
            "   [ 2.41993013e+02]\n",
            "   [-1.36742061e+01]\n",
            "   [ 4.72621039e-01]\n",
            "   [ 4.86522496e-01]\n",
            "   [-5.38981929e-01]\n",
            "   [ 4.99423362e-01]\n",
            "   [-7.25580703e+00]\n",
            "   [ 1.02034327e+01]\n",
            "   [ 9.43528821e+00]\n",
            "   [ 6.82203299e-01]\n",
            "   [ 4.17863570e+00]\n",
            "   [-5.43169188e+00]\n",
            "   [ 6.11870916e+00]]]]\n",
            "truth: \n",
            " [[[[-4.00206898e+01]\n",
            "   [-2.47253451e+02]\n",
            "   [-1.92222032e+02]\n",
            "   [ 5.41198380e-01]\n",
            "   [-8.40516550e-01]\n",
            "   [ 1.09723358e-03]\n",
            "   [-2.51999578e-02]\n",
            "   [ 3.51785727e+00]\n",
            "   [-1.25172220e+00]\n",
            "   [ 4.47370697e+00]]]\n",
            "\n",
            "\n",
            " [[[-6.75265329e+01]\n",
            "   [ 2.41993013e+02]\n",
            "   [-1.36742061e+01]\n",
            "   [ 4.72621039e-01]\n",
            "   [ 4.86522496e-01]\n",
            "   [-5.38981929e-01]\n",
            "   [ 4.99423362e-01]\n",
            "   [-7.25580703e+00]\n",
            "   [ 1.02034327e+01]\n",
            "   [ 9.43528821e+00]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbcNTfN1A7fv",
        "colab_type": "code",
        "outputId": "d11ada44-2394-4355-e658-662049bf5afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def testConvTransposeSize():\n",
        "  inputs = 14\n",
        "  x_test = torch.zeros(1,1,inputs,1)\n",
        "  up = nn.ConvTranspose2d(1, 1, (2,2*inputs), padding=0, stride=2)\n",
        "  up_test = up(x_test)\n",
        "  print('up: ', up_test.size())\n",
        "\n",
        "  down = nn.Conv2d(1,1, (1,inputs*2), padding=0, stride=3)\n",
        "  down_test = down(up_test)\n",
        "  print('down: ', down_test.size())\n",
        "\n",
        "testConvTransposeSize()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "up:  torch.Size([1, 1, 28, 28])\n",
            "down:  torch.Size([1, 1, 10, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9EXL6hvwr08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "class UBlock(nn.Module):\n",
        "  def __init__(self, c_in, c_out, after='none'):\n",
        "    super(UBlock, self).__init__()\n",
        "    self.main_net = nn.Sequential(\n",
        "        nn.Conv2d(c_in, c_out, (3,3), padding=(1,1)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(c_out, c_out, (3,3), padding=(1,1)),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    self.after = after\n",
        "    if after == 'up':\n",
        "      self.after_net = nn.ConvTranspose2d(c_out, c_out//2, (2,2), padding=0, stride=2)\n",
        "    elif after == 'down':\n",
        "      self.after_net = nn.Conv2d(c_out, c_out, (3,3), padding=(1,1), stride=2)\n",
        "    elif after == 'end':\n",
        "      self.after_net = nn.Conv2d(c_out,1, (1,14*2), padding=0, stride=3)\n",
        "    else: # none\n",
        "      self.after_net = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    main_out = self.main_net(x).squeeze(2).squeeze(2)\n",
        "    after_out = self.after_net(main_out).squeeze(2).squeeze(2)\n",
        "    if self.after == 'up':\n",
        "      b,c,h,w = main_out.shape\n",
        "      return main_out[:,:c//2,:,:], after_out\n",
        "    else:\n",
        "      return after_out\n",
        "\n",
        "class DynamicsNN(nn.Module):\n",
        "  def __init__(self, num_inputs=14):\n",
        "    super(DynamicsNN, self).__init__()\n",
        "    self.beg = nn.ConvTranspose2d(1, 1, (2,2*num_inputs), padding=0, stride=2)\n",
        "    self.up1 = UBlock(1, 512, after='up')\n",
        "    self.up2 = UBlock(256, 256, after='up')\n",
        "    self.up3 = UBlock(128, 128, after='up')\n",
        "    self.up4 = UBlock(64, 64, after='up')\n",
        "    self.dn1 = UBlock(32, 32, after='down')\n",
        "    self.dn2 = UBlock(64, 64, after='down')\n",
        "    self.dn3 = UBlock(128, 128, after='down')\n",
        "    self.dn4 = UBlock(256, 256, after='down')\n",
        "    self.end = UBlock(512, 512, after='end')\n",
        "\n",
        "  def forward(self, x_in):\n",
        "    # set_trace()\n",
        "    beg = self.beg(x_in)\n",
        "    skip1, up1 = self.up1(beg)\n",
        "    skip2, up2 = self.up2(up1)\n",
        "    skip3, up3 = self.up3(up2)\n",
        "    skip4, up4 = self.up4(up3)\n",
        "    down1 = self.dn1(up4)\n",
        "    down2 = self.dn2(torch.cat((skip4, down1), dim=1))\n",
        "    down3 = self.dn3(torch.cat((skip3, down2), dim=1))\n",
        "    down4 = self.dn4(torch.cat((skip2, down3), dim=1))\n",
        "    out = self.end(torch.cat((skip1, down4), dim=1))\n",
        "    out[:,:,3:7,:] /= torch.norm(out[:,:,3:7,:], dim=2).view(-1,1,1,1)\n",
        "    mask = (out[:,:,3,:] < 0).squeeze()\n",
        "    out[mask,:,3:7,:] *= -1\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0Mc_4YUWlt",
        "colab_type": "code",
        "outputId": "353528f8-2c0f-4b6d-9aa0-86ad88d29a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "def testNet():\n",
        "  x_test = torch.randn(1,1,14,1)\n",
        "  print('x_test: ', x_test[0,0,:,0])\n",
        "  net = DynamicsNN()\n",
        "  test = net(x_test)\n",
        "  print('shape: ', test.shape)\n",
        "  print('output: \\n', test[0,0,:,0])\n",
        "\n",
        "testNet()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test:  tensor([ 0.3742, -0.1727,  0.3634,  0.5274, -1.4375,  0.4241, -0.1815, -1.6557,\n",
            "         0.6278, -0.0034,  0.5984,  0.3879, -2.5938,  0.0033])\n",
            "shape:  torch.Size([1, 1, 10, 1])\n",
            "output: \n",
            " tensor([0.0069, 0.0086, 0.0076, 0.5317, 0.4460, 0.5338, 0.4832, 0.0092, 0.0112,\n",
            "        0.0088], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}