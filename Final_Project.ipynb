{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhask94/cs474_labs_f2019/blob/conv2linear/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpLgBkLMSCk",
        "colab_type": "code",
        "outputId": "c6cd87ed-3e09-48d2-8c1e-1de282d10c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# imports for training data\n",
        "!if ( ! ls . | grep pytransform ); then git clone https://github.com/mhask94/pytransform.git; fi\n",
        "# !git clone https://github.com/mhask94/pytransform.git\n",
        "from pytransform.common import skew\n",
        "from pytransform.quaternion import Quaternion as Quat\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytransform'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/14)\u001b[K\rremote: Counting objects:  14% (2/14)\u001b[K\rremote: Counting objects:  21% (3/14)\u001b[K\rremote: Counting objects:  28% (4/14)\u001b[K\rremote: Counting objects:  35% (5/14)\u001b[K\rremote: Counting objects:  42% (6/14)\u001b[K\rremote: Counting objects:  50% (7/14)\u001b[K\rremote: Counting objects:  57% (8/14)\u001b[K\rremote: Counting objects:  64% (9/14)\u001b[K\rremote: Counting objects:  71% (10/14)\u001b[K\rremote: Counting objects:  78% (11/14)\u001b[K\rremote: Counting objects:  85% (12/14)\u001b[K\rremote: Counting objects:  92% (13/14)\u001b[K\rremote: Counting objects: 100% (14/14)\u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects:  12% (1/8)\u001b[K\rremote: Compressing objects:  25% (2/8)\u001b[K\rremote: Compressing objects:  37% (3/8)\u001b[K\rremote: Compressing objects:  50% (4/8)\u001b[K\rremote: Compressing objects:  62% (5/8)\u001b[K\rremote: Compressing objects:  75% (6/8)\u001b[K\rremote: Compressing objects:  87% (7/8)\u001b[K\rremote: Compressing objects: 100% (8/8)\u001b[K\rremote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "Unpacking objects:   1% (1/65)   \rUnpacking objects:   3% (2/65)   \rUnpacking objects:   4% (3/65)   \rUnpacking objects:   6% (4/65)   \rUnpacking objects:   7% (5/65)   \rUnpacking objects:   9% (6/65)   \rUnpacking objects:  10% (7/65)   \rUnpacking objects:  12% (8/65)   \rUnpacking objects:  13% (9/65)   \rUnpacking objects:  15% (10/65)   \rUnpacking objects:  16% (11/65)   \rUnpacking objects:  18% (12/65)   \rUnpacking objects:  20% (13/65)   \rUnpacking objects:  21% (14/65)   \rUnpacking objects:  23% (15/65)   \rUnpacking objects:  24% (16/65)   \rremote: Total 65 (delta 6), reused 14 (delta 6), pack-reused 51\u001b[K\n",
            "Unpacking objects:  26% (17/65)   \rUnpacking objects:  27% (18/65)   \rUnpacking objects:  29% (19/65)   \rUnpacking objects:  30% (20/65)   \rUnpacking objects:  32% (21/65)   \rUnpacking objects:  33% (22/65)   \rUnpacking objects:  35% (23/65)   \rUnpacking objects:  36% (24/65)   \rUnpacking objects:  38% (25/65)   \rUnpacking objects:  40% (26/65)   \rUnpacking objects:  41% (27/65)   \rUnpacking objects:  43% (28/65)   \rUnpacking objects:  44% (29/65)   \rUnpacking objects:  46% (30/65)   \rUnpacking objects:  47% (31/65)   \rUnpacking objects:  49% (32/65)   \rUnpacking objects:  50% (33/65)   \rUnpacking objects:  52% (34/65)   \rUnpacking objects:  53% (35/65)   \rUnpacking objects:  55% (36/65)   \rUnpacking objects:  56% (37/65)   \rUnpacking objects:  58% (38/65)   \rUnpacking objects:  60% (39/65)   \rUnpacking objects:  61% (40/65)   \rUnpacking objects:  63% (41/65)   \rUnpacking objects:  64% (42/65)   \rUnpacking objects:  66% (43/65)   \rUnpacking objects:  67% (44/65)   \rUnpacking objects:  69% (45/65)   \rUnpacking objects:  70% (46/65)   \rUnpacking objects:  72% (47/65)   \rUnpacking objects:  73% (48/65)   \rUnpacking objects:  75% (49/65)   \rUnpacking objects:  76% (50/65)   \rUnpacking objects:  78% (51/65)   \rUnpacking objects:  80% (52/65)   \rUnpacking objects:  81% (53/65)   \rUnpacking objects:  83% (54/65)   \rUnpacking objects:  84% (55/65)   \rUnpacking objects:  86% (56/65)   \rUnpacking objects:  87% (57/65)   \rUnpacking objects:  89% (58/65)   \rUnpacking objects:  90% (59/65)   \rUnpacking objects:  92% (60/65)   \rUnpacking objects:  93% (61/65)   \rUnpacking objects:  95% (62/65)   \rUnpacking objects:  96% (63/65)   \rUnpacking objects:  98% (64/65)   \rUnpacking objects: 100% (65/65)   \rUnpacking objects: 100% (65/65), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFbSU4rzH849",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports for pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73-GfR1p7usv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes for quadrotor state and dynamics\n",
        "class State():\n",
        "    def __init__(self, arr=np.empty(0)):\n",
        "        if len(arr) == 0:\n",
        "            self.arr = np.zeros((10,1), dtype=np.float64)\n",
        "            self.arr[3] = 1\n",
        "        else:\n",
        "            assert arr.shape == (10, 1)\n",
        "            if not arr.dtype == np.float64:\n",
        "              arr = np.array(arr, dtype=np.float64)\n",
        "            arr.dtype = np.float64\n",
        "            self.arr = arr\n",
        "\n",
        "    def __getitem__(self, position):\n",
        "        return self.arr[position]\n",
        "    def __str__(self):\n",
        "        s = 'p: ' + str(self.p.flatten()) + '\\nq: ' + self.q.__str__() + \\\n",
        "                '\\nv: ' + str(self.v.flatten())\n",
        "        s = s.replace('[ ', '[')\n",
        "        s = s.replace(', ', ' ')\n",
        "        s = s.replace(' ]', ']')\n",
        "        return s\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "    def __add__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        out = np.empty(self.arr.shape)\n",
        "        out[:3]  = self.p + other[:3]\n",
        "        out[3:7] = (self.q + other[3:6]).elements\n",
        "        out[7:]  = self.v + other[6:]\n",
        "        return State(out)\n",
        "    def __iadd__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        self.arr[:3] += other[:3]\n",
        "        self.arr[3:7] = (self.q + other[3:6]).elements\n",
        "        self.arr[7:] += other[6:]\n",
        "        return self\n",
        "    @property\n",
        "    def p(self):\n",
        "        return self.arr[:3]\n",
        "    @property\n",
        "    def q(self):\n",
        "        return Quat(self.arr[3:7])\n",
        "    @property\n",
        "    def v(self):\n",
        "        return self.arr[7:]\n",
        "    @property\n",
        "    def elements(self):\n",
        "        return self.arr.copy()\n",
        "    def copy(self):\n",
        "        return State(self.arr.copy())\n",
        "\n",
        "class Dynamics():\n",
        "    def __init__(self):\n",
        "        self.k1 = np.zeros((9,1))\n",
        "        self.k2 = np.zeros((9,1))\n",
        "        self.k3 = np.zeros((9,1))\n",
        "        self.k4 = np.zeros((9,1))\n",
        "        self.cd = 0.1\n",
        "        e_z = np.array([[0,0,1]]).T\n",
        "        self.g = 9.8065 * e_z\n",
        "        self.se = 0.5\n",
        "\n",
        "    def run(self, xu, dt):\n",
        "        x,u = State(xu[:10]), xu[10:]\n",
        "        self.k1 = self.f(x, u)\n",
        "        self.k2 = self.f(x + self.k1*(dt/2), u)\n",
        "        self.k3 = self.f(x + self.k2*(dt/2), u)\n",
        "        self.k4 = self.f(x + self.k3*dt, u)\n",
        "        # x += (self.k1 + 2*(self.k2 + self.k3) + self.k4) * (dt/6)\n",
        "        return x + (self.k1 + 2*(self.k2 + self.k3) + self.k4) * (dt/6)\n",
        "\n",
        "    def f(self, x, u):\n",
        "        s, w = u[0], u[1:]\n",
        "        dx = np.empty(self.k1.shape)\n",
        "        dx[:3] = x.q.rota(x.v)\n",
        "        dx[3:6] = w\n",
        "        dx[6:] = -self.g*(s/self.se) - self.cd*x.v + x.q.rotp(self.g) - \\\n",
        "                skew(w) @ x.v\n",
        "        return dx\n",
        "\n",
        "    @property\n",
        "    def state(self):\n",
        "        return self.x.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oER-ve3bviM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator():\n",
        "  def __init__(self, num_states, num_inputs, dt=0.01, batch_size=50):\n",
        "    self.n = num_states\n",
        "    self.m = num_inputs\n",
        "    self.dt = dt\n",
        "    self.batch_size = batch_size\n",
        "    self.pos_lim = 50\n",
        "    self.att_lim = np.pi/3.5\n",
        "    self.vel_lim = 10\n",
        "    self.rate_lim = np.pi\n",
        "    self.s_lim = 1\n",
        "    self.dyn = Dynamics()\n",
        "\n",
        "  def getRandomInput(self):\n",
        "    xu = np.empty(self.n + self.m)\n",
        "    xu[:2] = np.random.uniform(-self.pos_lim, self.pos_lim, 2)\n",
        "    xu[2] = np.random.uniform(-self.pos_lim, 0)\n",
        "    mask = np.random.uniform(size=3) > 0.2\n",
        "    euler = np.random.uniform(-self.att_lim, self.att_lim, 3) * mask\n",
        "    xu[3:7] = Quat.from_euler(*euler).elements.flatten()\n",
        "    xu[7:10] = np.random.uniform(-self.vel_lim, self.vel_lim, 3)\n",
        "    xu[10] = np.random.uniform(0, self.s_lim)\n",
        "    xu[11:] = np.random.uniform(-self.rate_lim, self.rate_lim, 3)\n",
        "    return xu\n",
        "\n",
        "  def getBatch(self):\n",
        "    batch_in = np.empty((self.batch_size, self.n+self.m))\n",
        "    batch_out = np.empty((self.batch_size, self.n))\n",
        "    for i in range(self.batch_size):\n",
        "      batch_in[i] = self.getRandomInput()\n",
        "      batch_out[i] = self.dyn.run(batch_in[i].reshape(-1,1), self.dt).elements.flatten()\n",
        "    return batch_in, batch_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4SMzucDAkn5",
        "colab_type": "code",
        "outputId": "73a2ef57-2680-430d-db0c-e6ddf986bf56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "def testGen():\n",
        "  data_gen = DataGenerator(10,4,dt=0.01,batch_size=2)\n",
        "  ran = data_gen.getRandomInput()\n",
        "  print('rand: ', ran)\n",
        "\n",
        "  x, truth = data_gen.getBatch()\n",
        "  print('x: \\n', x)\n",
        "  print('truth: \\n', truth)\n",
        "\n",
        "  dyn = Dynamics()\n",
        "  for i, state in enumerate(x):\n",
        "    state = state.reshape(-1,1)\n",
        "    out = dyn.run(state, 0.01).elements.flatten()\n",
        "    error = out - truth[i]\n",
        "    norm = np.sqrt(error @ error)\n",
        "    print('norm: ', norm)\n",
        "\n",
        "testGen()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rand:  [-3.81085565e+01 -3.91763828e+01 -3.63731190e+01  9.81004447e-01\n",
            "  9.76446524e-03 -1.92829636e-03 -1.93729739e-01 -6.42299717e+00\n",
            " -4.28974423e+00  6.92848157e-02  9.40049592e-01  2.85486518e+00\n",
            " -9.69561734e-01 -1.70965377e+00]\n",
            "x: \n",
            " [[-4.71541780e+01 -3.72224203e+01 -3.14312599e+01  9.01655870e-01\n",
            "  -1.38416736e-01  2.52143653e-01 -3.22925810e-01  7.40986180e+00\n",
            "  -8.54192238e+00 -8.08164061e+00  9.99742037e-01  2.93108603e+00\n",
            "  -1.53090796e+00 -2.90044392e+00]\n",
            " [-1.18729001e+01 -1.15910614e+01 -9.99342729e+00  9.30630159e-01\n",
            "  -3.59331179e-01 -6.28030293e-02 -2.94005237e-02 -8.25515893e+00\n",
            "  -7.40695137e-01 -4.56977033e+00  7.40130835e-01  2.89424880e+00\n",
            "   5.00275231e-01  4.19208831e-01]]\n",
            "truth: \n",
            " [[-4.71932128e+01 -3.73421067e+01 -3.14908436e+01  9.00713336e-01\n",
            "  -1.31298169e-01  2.38442048e-01 -3.38558217e-01  7.49282871e+00\n",
            "  -8.59340939e+00 -8.04989235e+00]\n",
            " [-1.19509132e+01 -1.16269481e+01 -1.00334582e+01  9.35946249e-01\n",
            "  -3.45882854e-01 -6.01406484e-02 -2.74367032e-02 -8.21407446e+00\n",
            "  -9.03062681e-01 -4.65479378e+00]]\n",
            "norm:  0.0\n",
            "norm:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XvwSOVc3-Sy",
        "colab_type": "code",
        "outputId": "d0ac1b46-f0e6-4545-917a-8cfe556ba0c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def testLinearSize():\n",
        "  inputs = 14\n",
        "  outputs = 10\n",
        "  batch = 1\n",
        "  x_test = torch.zeros(batch,inputs)\n",
        "  up = nn.Linear(inputs, 50)\n",
        "  up_test = up(x_test)\n",
        "  print('up: ', up_test.size())\n",
        "\n",
        "  down = nn.Linear(50, outputs)\n",
        "  down_test = down(up_test)\n",
        "  print('down: ', down_test.size())\n",
        "\n",
        "testLinearSize()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "up:  torch.Size([1, 50])\n",
            "down:  torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9EXL6hvwr08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, dim_in, dim_out, skip=False, end=False):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.skip = skip\n",
        "    self.end = end\n",
        "    self.activation = nn.ReLU()\n",
        "    self.layer1 = nn.Linear(dim_in, dim_in)\n",
        "    self.layer2 = nn.Linear(dim_in, dim_in)\n",
        "    self.layer3 = nn.Linear(dim_in, dim_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = self.activation(self.layer1(x))\n",
        "    out2 = self.layer2(out1)\n",
        "    skip = self.activation(out2 + out1)\n",
        "    if self.end:\n",
        "      out3 = self.layer3(skip)\n",
        "    else:\n",
        "      out3 = self.activation(self.layer3(skip))\n",
        "    if self.skip:\n",
        "      return skip, out3\n",
        "    else:\n",
        "      return out3\n",
        "\n",
        "class DynamicsNN(nn.Module):\n",
        "  def __init__(self, num_states, num_inputs, dt):\n",
        "    super(DynamicsNN, self).__init__()\n",
        "    self.dt = dt\n",
        "    self.activation = nn.ReLU()\n",
        "    self.up1 = nn.Linear(num_states+num_inputs, 50)\n",
        "    self.up2 = ResBlock(50,  100, skip=True)\n",
        "    self.up3 = ResBlock(100, 200, skip=True)\n",
        "    self.dn1 = ResBlock(200, 100)\n",
        "    self.dn2 = ResBlock(100, 50)\n",
        "    self.dn3 = ResBlock(50,  num_states, end=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    up1 = self.activation(self.up1(x))\n",
        "    skip1, up2 = self.up2(up1)\n",
        "    skip2, up3 = self.up3(up2)\n",
        "    down1 = self.dn1(up3)\n",
        "    down2 = self.dn2(skip2 + down1)\n",
        "    down3 = self.dn3(skip1 + down2)\n",
        "    p = down3[:,:3] + x[:,:3] + x[:,7:10]*self.dt\n",
        "    w = torch.zeros_like(down3[:,3:7])\n",
        "    w[:,1:] = x[:,4:7]\n",
        "    q = down3[:,3:7] + x[:,3:7] + w*self.dt\n",
        "    q1 = torch.zeros_like(q)\n",
        "    q1 = q / torch.norm(q, dim=1, keepdim=True)\n",
        "    # was getting nans here, but removing ReLU on output layer fixed it\n",
        "    # norm = torch.norm(q, dim=1)\n",
        "    # mask = norm != 0.0\n",
        "    # q1[mask] = q[mask] / norm[mask].unsqueeze(-1)\n",
        "    v = down3[:,7:] + x[:,7:10]\n",
        "    out = torch.cat((p,q1,v), dim=1)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0Mc_4YUWlt",
        "colab_type": "code",
        "outputId": "c40218ae-4a04-469f-da01-1d5fb525570f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "def testNet():\n",
        "  n = 10\n",
        "  m = 4\n",
        "  dt = 0.01\n",
        "  x_test = torch.randn(2,n+m)\n",
        "  print('x_test: ', x_test)\n",
        "  net = DynamicsNN(n,m, dt)\n",
        "  test = net(x_test)\n",
        "  print('shape: ', test.shape)\n",
        "  print('output: ', test)\n",
        "\n",
        "testNet()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test:  tensor([[ 0.6027, -0.4907,  0.1397, -1.6363,  0.1256, -0.6441, -1.5072, -0.2153,\n",
            "         -0.1257, -0.3266, -1.6617,  0.5776,  0.7538, -0.6094],\n",
            "        [ 1.9939, -0.7580, -1.0585, -0.2426,  1.0348,  2.2233,  0.3213,  0.8090,\n",
            "         -0.2408,  1.0777, -0.0496,  0.6603,  0.2110,  0.2761]])\n",
            "shape:  torch.Size([2, 10])\n",
            "output:  tensor([[ 0.6789, -0.5257,  0.1323, -0.7044, -0.0109, -0.3051, -0.6407, -0.2535,\n",
            "         -0.0627, -0.3274],\n",
            "        [ 2.0916, -0.7751, -1.0550, -0.0193,  0.3719,  0.9064,  0.1996,  0.7377,\n",
            "         -0.1814,  1.0955]], grad_fn=<CatBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSv0Pa_ezzXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, optimizer, loss_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_yf9ICTpBo",
        "colab_type": "code",
        "outputId": "6cb81a9f-f154-4190-a3bc-79e9e0a691b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "def train(save_model):\n",
        "  n = 10\n",
        "  m = 4\n",
        "  dt = 0.01\n",
        "  model = DynamicsNN(n, m, dt).cuda()\n",
        "\n",
        "  lr = 1e-5\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  epochs = 1000\n",
        "  batch_size = 500\n",
        "  data_gen = DataGenerator(n, m, dt, batch_size)\n",
        "\n",
        "  save_every = 10\n",
        "  decay_every = 100\n",
        "  # validate_every = 1000\n",
        "\n",
        "  epoch_hist = []\n",
        "  loss_hist = []\n",
        "  # vals = []\n",
        "\n",
        "  num_nans = 0\n",
        "\n",
        "  last_l = 0\n",
        "  last_e = 0\n",
        "  info = tqdm(total=epochs, position=0, leave=False)\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    xu_t, x_tp1 = data_gen.getBatch()\n",
        "    in_var = Variable(torch.from_numpy(xu_t).float(), requires_grad=True).cuda()\n",
        "    out_truth = Variable(torch.from_numpy(x_tp1).float(), requires_grad=False).cuda()\n",
        "\n",
        "    out_pred = model(in_var)\n",
        "\n",
        "    position_loss = loss_fn(out_pred[:,:3], out_truth[:,:3])\n",
        "    attitude_loss = loss_fn(out_pred[:,3:7]*100, out_truth[:,3:7]*100)\n",
        "    velocity_loss = loss_fn(out_pred[:,7:], out_truth[:,7:])\n",
        "    loss = position_loss + attitude_loss + velocity_loss \n",
        "    #loss = loss_fn(out_pred, out_truth)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # was getting nans in out_pred and loss because / by 0 in norm calculation \n",
        "    # until I removed ReLU from last layer\n",
        "    loss = loss.item()\n",
        "    if np.isnan(loss):\n",
        "      num_nans += 1\n",
        "\n",
        "    # if epoch % validate_every == 0:\n",
        "      # validate()\n",
        "\n",
        "    if epoch % save_every == 0:\n",
        "      last_l = loss\n",
        "      last_e = epoch\n",
        "      epoch_hist.append(epoch)\n",
        "      loss_hist.append(loss)\n",
        "      if save_model:\n",
        "        torch.save(model, 'learned_quadrotor_model.pt')\n",
        "    \n",
        "    if epoch % decay_every == 0:\n",
        "      lr *= 0.9\n",
        "      for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    \n",
        "    info.set_description('Last saved loss: {:.3f}, e: {}'.format(last_l,last_e))\n",
        "    info.update(1)\n",
        "  \n",
        "  fig, ax = plt.subplots()\n",
        "  train_losses, = ax.plot(epoch_hist, loss_hist, 'b', label='train')\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Loss')\n",
        "  ax.legend()\n",
        "  print('\\nNans: ', num_nans)\n",
        "  print('sample input: ', xu_t[0])\n",
        "  print('true output: ', x_tp1[0])\n",
        "  print('predicted output: ', out_pred[0])\n",
        "  plt.show()\n",
        "\n",
        "train(save_model=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last saved loss: 98.373, e: 990: 100%|██████████| 1000/1000 [03:16<00:00,  5.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Nans:  0\n",
            "sample input:  [  9.31781675  25.31751542 -34.80151406   0.98960562   0.\n",
            "   0.           0.14380791  -1.27667522  -5.12424687  -8.90926277\n",
            "   0.11808945  -1.01724059   2.4267579    1.89107203]\n",
            "true output:  [ 9.32016105e+00  2.52647844e+01 -3.48901878e+01  9.88116041e-01\n",
            " -6.77797337e-03  1.12757368e-02  1.53145703e-01 -1.15625096e+00\n",
            " -5.00605151e+00 -8.90650355e+00]\n",
            "predicted output:  tensor([ 8.7857e+00,  2.5015e+01, -3.5076e+01,  9.9469e-01, -2.1614e-02,\n",
            "         5.6145e-02,  8.3452e-02, -1.3131e+00, -6.2060e+00, -9.2282e+00],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niigpiIhIESUFEREp8v+k9D9U5npy0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRH6lj6psnH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4d276840-f8f9-4ad3-c139-9de4f17c0c7d"
      },
      "source": [
        "x_test = torch.tensor([[0,0,0,1,0,0,0,0,0,0,0.8,0,0,0]])\n",
        "model(x_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-33d882432b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}