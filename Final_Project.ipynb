{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhask94/cs474_labs_f2019/blob/conv2linear/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpLgBkLMSCk",
        "colab_type": "code",
        "outputId": "5bfa2a18-bb46-4313-bcac-c94cb862fb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# imports for training data\n",
        "!if ( ! ls . | grep pytransform ); then git clone https://github.com/mhask94/pytransform.git; fi\n",
        "# !git clone https://github.com/mhask94/pytransform.git\n",
        "from pytransform.common import skew\n",
        "from pytransform.quaternion import Quaternion as Quat\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytransform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFbSU4rzH849",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports for pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73-GfR1p7usv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes for quadrotor state and dynamics\n",
        "class State():\n",
        "    def __init__(self, arr=np.empty(0)):\n",
        "        if len(arr) == 0:\n",
        "            self.arr = np.zeros((10,1), dtype=np.float64)\n",
        "            self.arr[3] = 1\n",
        "        else:\n",
        "            assert arr.shape == (10, 1)\n",
        "            if not arr.dtype == np.float64:\n",
        "              arr = np.array(arr, dtype=np.float64)\n",
        "            arr.dtype = np.float64\n",
        "            self.arr = arr\n",
        "\n",
        "    def __getitem__(self, position):\n",
        "        return self.arr[position]\n",
        "    def __str__(self):\n",
        "        s = 'p: ' + str(self.p.flatten()) + '\\nq: ' + self.q.__str__() + \\\n",
        "                '\\nv: ' + str(self.v.flatten())\n",
        "        s = s.replace('[ ', '[')\n",
        "        s = s.replace(', ', ' ')\n",
        "        s = s.replace(' ]', ']')\n",
        "        return s\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "    def __add__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        out = np.empty(self.arr.shape)\n",
        "        out[:3]  = self.p + other[:3]\n",
        "        out[3:7] = (self.q + other[3:6]).elements\n",
        "        out[7:]  = self.v + other[6:]\n",
        "        return State(out)\n",
        "    def __iadd__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        self.arr[:3] += other[:3]\n",
        "        self.arr[3:7] = (self.q + other[3:6]).elements\n",
        "        self.arr[7:] += other[6:]\n",
        "        return self\n",
        "    @property\n",
        "    def p(self):\n",
        "        return self.arr[:3]\n",
        "    @property\n",
        "    def q(self):\n",
        "        return Quat(self.arr[3:7])\n",
        "    @property\n",
        "    def v(self):\n",
        "        return self.arr[7:]\n",
        "    @property\n",
        "    def elements(self):\n",
        "        return self.arr.copy()\n",
        "    def copy(self):\n",
        "        return State(self.arr.copy())\n",
        "\n",
        "class Dynamics():\n",
        "    def __init__(self):\n",
        "        self.k1 = np.zeros((9,1))\n",
        "        self.k2 = np.zeros((9,1))\n",
        "        self.k3 = np.zeros((9,1))\n",
        "        self.k4 = np.zeros((9,1))\n",
        "        self.cd = 0.1\n",
        "        e_z = np.array([[0,0,1]]).T\n",
        "        self.g = 9.8065 * e_z\n",
        "        self.se = 0.5\n",
        "\n",
        "    def run(self, xu, dt):\n",
        "        x,u = State(xu[:10]), xu[10:]\n",
        "        self.k1 = self.f(x, u)\n",
        "        self.k2 = self.f(x + self.k1*(dt/2), u)\n",
        "        self.k3 = self.f(x + self.k2*(dt/2), u)\n",
        "        self.k4 = self.f(x + self.k3*dt, u)\n",
        "        # x += (self.k1 + 2*(self.k2 + self.k3) + self.k4) * (dt/6)\n",
        "        return x + (self.k1 + 2*(self.k2 + self.k3) + self.k4) * (dt/6)\n",
        "\n",
        "    def f(self, x, u):\n",
        "        s, w = u[0], u[1:]\n",
        "        dx = np.empty(self.k1.shape)\n",
        "        dx[:3] = x.q.rota(x.v)\n",
        "        dx[3:6] = w\n",
        "        dx[6:] = -self.g*(s/self.se) - self.cd*x.v + x.q.rotp(self.g) - \\\n",
        "                skew(w) @ x.v\n",
        "        return dx\n",
        "\n",
        "    @property\n",
        "    def state(self):\n",
        "        return self.x.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oER-ve3bviM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator():\n",
        "  def __init__(self, num_states, num_inputs, dt=0.01, batch_size=50):\n",
        "    self.n = num_states\n",
        "    self.m = num_inputs\n",
        "    self.dt = dt\n",
        "    self.batch_size = batch_size\n",
        "    self.pos_lim = 50\n",
        "    self.att_lim = np.pi/3.5\n",
        "    self.vel_lim = 10\n",
        "    self.rate_lim = np.pi\n",
        "    self.s_lim = 1\n",
        "    self.dyn = Dynamics()\n",
        "\n",
        "  def getRandomInput(self):\n",
        "    xu = np.empty(self.n + self.m)\n",
        "    xu[:2] = np.random.uniform(-self.pos_lim, self.pos_lim, 2)\n",
        "    xu[2] = np.random.uniform(-self.pos_lim, 0)\n",
        "    mask = np.random.uniform(size=3) > 0.2\n",
        "    euler = np.random.uniform(-self.att_lim, self.att_lim, 3) * mask\n",
        "    xu[3:7] = Quat.from_euler(*euler).elements.flatten()\n",
        "    xu[7:10] = np.random.uniform(-self.vel_lim, self.vel_lim, 3)\n",
        "    xu[10] = np.random.uniform(0, self.s_lim)\n",
        "    xu[11:] = np.random.uniform(-self.rate_lim, self.rate_lim, 3)\n",
        "    return xu\n",
        "\n",
        "  def getBatch(self):\n",
        "    batch_in = np.empty((self.batch_size, self.n+self.m))\n",
        "    batch_out = np.empty((self.batch_size, self.n))\n",
        "    for i in range(self.batch_size):\n",
        "      batch_in[i] = self.getRandomInput()\n",
        "      batch_out[i] = self.dyn.run(batch_in[i].reshape(-1,1), self.dt).elements.flatten()\n",
        "    return batch_in, batch_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4SMzucDAkn5",
        "colab_type": "code",
        "outputId": "323ace8e-39c3-4658-f85d-7256a03646a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "def testGen():\n",
        "  data_gen = DataGenerator(10,4,dt=0.01,batch_size=2)\n",
        "  ran = data_gen.getRandomInput()\n",
        "  print('rand: ', ran)\n",
        "\n",
        "  x, truth = data_gen.getBatch()\n",
        "  print('x: \\n', x)\n",
        "  print('truth: \\n', truth)\n",
        "\n",
        "  dyn = Dynamics()\n",
        "  for i, state in enumerate(x):\n",
        "    state = state.reshape(-1,1)\n",
        "    out = dyn.run(state, 0.01).elements.flatten()\n",
        "    error = out - truth[i]\n",
        "    norm = np.sqrt(error @ error)\n",
        "    print('norm: ', norm)\n",
        "\n",
        "testGen()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rand:  [ 22.65623071 -35.85586152 -47.59118468   0.95669956  -0.16721869\n",
            "   0.23286565  -0.05037311   5.71689689   2.83455618  -8.99871764\n",
            "   0.73392403  -2.0871038    0.7375327    2.83241342]\n",
            "x: \n",
            " [[ 4.95461307e+01 -1.04381575e+01 -4.08774910e+00  9.92667362e-01\n",
            "   0.00000000e+00 -0.00000000e+00  1.20878076e-01 -4.25005858e+00\n",
            "  -5.40683417e+00 -5.27396585e+00  3.40692169e-01  2.50896058e-01\n",
            "  -2.48720275e+00  2.53417490e+00]\n",
            " [-4.48435963e+01 -3.58206118e+01 -9.04043260e+00  9.90930234e-01\n",
            "   2.65701120e-02  3.53069555e-03  1.31677012e-01  5.82027552e+00\n",
            "   7.31445909e+00  6.06692916e+00  4.58223888e-01  1.70578023e+00\n",
            "   1.54370443e+00  2.38300886e+00]]\n",
            "truth: \n",
            " [[ 4.95178644e+01 -1.05008129e+01 -4.14030620e+00  9.90978587e-01\n",
            "   2.74837795e-03 -1.21925420e-02  1.33436230e-01 -4.50939209e+00\n",
            "  -5.30339047e+00 -5.11514685e+00]\n",
            " [-4.48056670e+01 -3.57380617e+01 -8.97592129e+00  9.88971618e-01\n",
            "   3.40433888e-02  1.19848180e-02  1.43640353e-01  5.89418392e+00\n",
            "   7.27688934e+00  6.03484960e+00]]\n",
            "norm:  0.0\n",
            "norm:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XvwSOVc3-Sy",
        "colab_type": "code",
        "outputId": "9bb60813-69ec-4ea1-db76-61025da565df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def testLinearSize():\n",
        "  inputs = 14\n",
        "  outputs = 10\n",
        "  batch = 1\n",
        "  x_test = torch.zeros(batch,inputs)\n",
        "  up = nn.Linear(inputs, 50)\n",
        "  up_test = up(x_test)\n",
        "  print('up: ', up_test.size())\n",
        "\n",
        "  down = nn.Linear(50, outputs)\n",
        "  down_test = down(up_test)\n",
        "  print('down: ', down_test.size())\n",
        "\n",
        "testLinearSize()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "up:  torch.Size([1, 50])\n",
            "down:  torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9EXL6hvwr08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, dim_in, dim_out, skip=False):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.skip = skip\n",
        "    self.activation = nn.ReLU()\n",
        "    self.layer1 = nn.Linear(dim_in, dim_in)\n",
        "    self.layer2 = nn.Linear(dim_in, dim_in)\n",
        "    self.layer3 = nn.Linear(dim_in, dim_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = self.activation(self.layer1(x))\n",
        "    out2 = self.layer2(out1)\n",
        "    skip = self.activation(out2 + out1)\n",
        "    out3 = self.layer3(skip)\n",
        "    if self.skip:\n",
        "      return skip, out3\n",
        "    else:\n",
        "      return out3\n",
        "\n",
        "class DynamicsNN(nn.Module):\n",
        "  def __init__(self, num_states, num_inputs):\n",
        "    super(DynamicsNN, self).__init__()\n",
        "    self.up1 = nn.Linear(num_states+num_inputs, 50)\n",
        "    self.up2 = ResBlock(50,  100, skip=True)\n",
        "    self.up3 = ResBlock(100, 200, skip=True)\n",
        "    self.dn1 = ResBlock(200, 100)\n",
        "    self.dn2 = ResBlock(100, 50)\n",
        "    self.dn3 = ResBlock(50,  num_states)\n",
        "\n",
        "  def forward(self, x):\n",
        "    up1 = self.up1(x)\n",
        "    skip1, up2 = self.up2(up1)\n",
        "    skip2, up3 = self.up3(up2)\n",
        "    down1 = self.dn1(up3)\n",
        "    down2 = self.dn2(skip2 + down1)\n",
        "    down3 = self.dn3(skip1 + down2)\n",
        "    p = down3[:,:3]\n",
        "    q = down3[:,3:7]\n",
        "    q1 = torch.zeros_like(q)\n",
        "    q1 = q / torch.norm(q, dim=1, keepdim=True)\n",
        "    # was getting nans here, but removing ReLU on output layer fixed it\n",
        "    # norm = torch.norm(q, dim=1)\n",
        "    # mask = norm != 0.0\n",
        "    # q1[mask] = q[mask] / norm[mask].unsqueeze(-1)\n",
        "    v = down3[:,7:]\n",
        "    out = torch.cat((p,q1,v), dim=1)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0Mc_4YUWlt",
        "colab_type": "code",
        "outputId": "e3e1af28-68a8-4d14-83cf-5f954ae02e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "def testNet():\n",
        "  n = 10\n",
        "  m = 4\n",
        "  x_test = torch.randn(2,n+m)\n",
        "  print('x_test: ', x_test)\n",
        "  net = DynamicsNN(n,m)\n",
        "  test = net(x_test)\n",
        "  print('shape: ', test.shape)\n",
        "  print('output: ', test)\n",
        "\n",
        "testNet()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test:  tensor([[-0.9540, -0.8776,  0.1494, -0.2397,  1.8163,  0.2107, -0.0744, -1.0588,\n",
            "         -1.8483,  1.1765,  0.3127, -1.1399, -1.9557, -0.0269],\n",
            "        [ 0.3101, -1.1544, -0.7812, -1.5217,  1.0783, -0.5044, -0.2738,  0.3796,\n",
            "          0.1178, -1.2005,  0.8041, -0.7604,  2.3362,  0.1348]])\n",
            "shape:  torch.Size([2, 10])\n",
            "output:  tensor([[-0.1095, -0.0120, -0.0925, -0.8100,  0.1639,  0.4073,  0.3887,  0.0257,\n",
            "         -0.0463,  0.1235],\n",
            "        [ 0.0043,  0.0660, -0.0024, -0.5319, -0.1130,  0.4270,  0.7225, -0.0442,\n",
            "         -0.1009,  0.0074]], grad_fn=<CatBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_yf9ICTpBo",
        "colab_type": "code",
        "outputId": "b3601adc-ef45-4ffb-e192-0dcfb3890558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        }
      },
      "source": [
        "def train(save_model):\n",
        "  n = 10\n",
        "  m = 4\n",
        "  dt = 0.01\n",
        "  model = DynamicsNN(n, m).cuda()\n",
        "\n",
        "  lr = 1e-4\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  epochs = 1000\n",
        "  batch_size = 500\n",
        "  data_gen = DataGenerator(n, m, dt, batch_size)\n",
        "\n",
        "  save_every = 10\n",
        "  decay_every = 100\n",
        "  # validate_every = 1000\n",
        "\n",
        "  epoch_hist = []\n",
        "  loss_hist = []\n",
        "  # vals = []\n",
        "\n",
        "  num_nans = 0\n",
        "\n",
        "  last_l = 0\n",
        "  last_e = 0\n",
        "  info = tqdm(total=epochs, position=0, leave=False)\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    xu_t, x_tp1 = data_gen.getBatch()\n",
        "    in_var = Variable(torch.from_numpy(xu_t).float(), requires_grad=True).cuda()\n",
        "    out_truth = Variable(torch.from_numpy(x_tp1).float(), requires_grad=False).cuda()\n",
        "\n",
        "    out_pred = model(in_var)\n",
        "\n",
        "    loss = loss_fn(out_pred, out_truth)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # was getting nans in out_pred and loss because / by 0 in norm calculation \n",
        "    # until I removed ReLU from last layer\n",
        "    loss = loss.item()\n",
        "    if np.isnan(loss):\n",
        "      num_nans += 1\n",
        "\n",
        "    # if epoch % validate_every == 0:\n",
        "      # validate()\n",
        "\n",
        "    if epoch % save_every == 0:\n",
        "      last_l = loss\n",
        "      last_e = epoch\n",
        "      epoch_hist.append(epoch)\n",
        "      loss_hist.append(loss)\n",
        "      if save_model:\n",
        "        torch.save(model, 'learned_quadrotor_model.pt')\n",
        "    \n",
        "    if epoch % decay_every == 0:\n",
        "      lr *= 0.9\n",
        "      for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    \n",
        "    info.set_description('Last saved loss: {:.3f}, e: {}'.format(last_l,last_e))\n",
        "    info.update(1)\n",
        "  \n",
        "  fig, ax = plt.subplots()\n",
        "  train_losses, = ax.plot(epoch_hist, loss_hist, 'b', label='train')\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Loss')\n",
        "  ax.legend()\n",
        "  print('\\nNans: ', num_nans)\n",
        "  print('sample input: ', xu_t[0])\n",
        "  print('sample output: ', out_pred[0])\n",
        "  plt.show()\n",
        "\n",
        "train(save_model=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Last saved loss: 8.958, e: 0: 100%|██████████| 1000/1000 [05:23<00:00,  2.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Nans:  0\n",
            "sample input:  [ 3.34865365e+01 -1.60931820e+01 -8.21533548e+00  9.56984488e-01\n",
            "  2.89295724e-01 -6.39672523e-03 -2.11602395e-02 -3.14389180e+00\n",
            " -5.32152168e+00 -2.60110001e+00  4.02530445e-01 -2.07895210e+00\n",
            " -2.53855378e+00 -2.69042179e-01]\n",
            "sample output:  tensor([ 32.7074, -16.9107,  -8.4199,   0.9589,   0.0955,   0.2511,  -0.0912,\n",
            "         -0.4504,   0.0514,  -0.2369], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBRERaaVQEBGRVgoFERFp9f8BVMTsM6XgUU4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRH6lj6psnH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "4d276840-f8f9-4ad3-c139-9de4f17c0c7d"
      },
      "source": [
        "x_test = torch.tensor([[0,0,0,1,0,0,0,0,0,0,0.8,0,0,0]])\n",
        "model(x_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-33d882432b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}