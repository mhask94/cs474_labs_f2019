{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Final_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhask94/cs474_labs_f2019/blob/conv2linear/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpLgBkLMSCk",
        "colab_type": "code",
        "outputId": "afea831b-2e44-47df-879d-79d2b34093ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# imports for training data\n",
        "!if ( ! ls . | grep pytransform ); then git clone https://github.com/mhask94/pytransform.git; fi\n",
        "# !git clone https://github.com/mhask94/pytransform.git\n",
        "from pytransform.common import skew\n",
        "from pytransform.quaternion import Quaternion as Quat\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pytransform\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFbSU4rzH849",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports for pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73-GfR1p7usv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classes for quadrotor state and dynamics\n",
        "class State():\n",
        "    def __init__(self, arr=np.empty(0)):\n",
        "        if len(arr) == 0:\n",
        "            self.arr = np.zeros((10,1), dtype=np.float64)\n",
        "            self.arr[3] = 1\n",
        "        else:\n",
        "            assert arr.shape == (10, 1)\n",
        "            if not arr.dtype == np.float64:\n",
        "              arr = np.array(arr, dtype=np.float64)\n",
        "            arr.dtype = np.float64\n",
        "            self.arr = arr\n",
        "\n",
        "    def __getitem__(self, position):\n",
        "        return self.arr[position]\n",
        "    def __str__(self):\n",
        "        s = 'p: ' + str(self.p.flatten()) + '\\nq: ' + self.q.__str__() + \\\n",
        "                '\\nv: ' + str(self.v.flatten())\n",
        "        s = s.replace('[ ', '[')\n",
        "        s = s.replace(', ', ' ')\n",
        "        s = s.replace(' ]', ']')\n",
        "        return s\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "    def __add__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        out = np.empty(self.arr.shape)\n",
        "        out[:3]  = self.p + other[:3]\n",
        "        out[3:7] = (self.q + other[3:6]).elements\n",
        "        out[7:]  = self.v + other[6:]\n",
        "        return State(out)\n",
        "    def __iadd__(self, other):\n",
        "        assert other.shape == (9, 1)\n",
        "        self.arr[:3] += other[:3]\n",
        "        self.arr[3:7] = (self.q + other[3:6]).elements\n",
        "        self.arr[7:] += other[6:]\n",
        "        return self\n",
        "    @property\n",
        "    def p(self):\n",
        "        return self.arr[:3]\n",
        "    @property\n",
        "    def q(self):\n",
        "        return Quat(self.arr[3:7])\n",
        "    @property\n",
        "    def v(self):\n",
        "        return self.arr[7:]\n",
        "    @property\n",
        "    def elements(self):\n",
        "        return self.arr.copy()\n",
        "    def copy(self):\n",
        "        return State(self.arr.copy())\n",
        "\n",
        "class Dynamics():\n",
        "    def __init__(self):\n",
        "        self.k1 = np.zeros((9,1))\n",
        "        self.k2 = np.zeros((9,1))\n",
        "        self.k3 = np.zeros((9,1))\n",
        "        self.k4 = np.zeros((9,1))\n",
        "        self.cd = 0.1\n",
        "        e_z = np.array([[0,0,1]]).T\n",
        "        self.g = 9.8065 * e_z\n",
        "        self.se = 0.5\n",
        "\n",
        "    def run(self, xu, dt):\n",
        "        x,u = State(xu[:10]), xu[10:]\n",
        "        self.k1 = self.f(x, u)\n",
        "        self.k2 = self.f(x + self.k1*(dt/2), u)\n",
        "        self.k3 = self.f(x + self.k2*(dt/2), u)\n",
        "        self.k4 = self.f(x + self.k3*dt, u)\n",
        "        # x += (self.k1 + 2*(self.k2 + self.k3) + self.k4) * (dt/6)\n",
        "        return x + (self.k1 + 2*(self.k2 + self.k3) + self.k4) * (dt/6)\n",
        "\n",
        "    def f(self, x, u):\n",
        "        s, w = u[0], u[1:]\n",
        "        dx = np.empty(self.k1.shape)\n",
        "        dx[:3] = x.q.rota(x.v)\n",
        "        dx[3:6] = w\n",
        "        dx[6:] = -self.g*(s/self.se) - self.cd*x.v + x.q.rotp(self.g) - \\\n",
        "                skew(w) @ x.v\n",
        "        return dx\n",
        "\n",
        "    @property\n",
        "    def state(self):\n",
        "        return self.x.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oER-ve3bviM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator():\n",
        "  def __init__(self, num_states, num_inputs, dt=0.01, batch_size=50):\n",
        "    self.n = num_states\n",
        "    self.m = num_inputs\n",
        "    self.dt = dt\n",
        "    self.batch_size = batch_size\n",
        "    self.pos_lim = 300\n",
        "    self.att_lim = np.pi\n",
        "    self.vel_lim = 10\n",
        "    self.rate_lim = 2*np.pi\n",
        "    self.s_lim = 1\n",
        "    self.dyn = Dynamics()\n",
        "\n",
        "  def getRandomInput(self):\n",
        "    xu = np.empty(self.n + self.m)\n",
        "    xu[:2] = np.random.uniform(-self.pos_lim, self.pos_lim, 2)\n",
        "    xu[2] = np.random.uniform(-self.pos_lim, 0)\n",
        "    mask = np.random.uniform(size=3) > 0.2\n",
        "    euler = np.random.uniform(-self.att_lim, self.att_lim, 3) * mask\n",
        "    xu[3:7] = Quat.from_euler(*euler).elements.flatten()\n",
        "    xu[7:10] = np.random.uniform(-self.vel_lim, self.vel_lim, 3)\n",
        "    xu[10] = np.random.uniform(0, self.s_lim)\n",
        "    xu[11:] = np.random.uniform(-self.rate_lim, self.rate_lim, 3)\n",
        "    return xu\n",
        "\n",
        "  def getBatch(self):\n",
        "    batch_in = np.empty((self.batch_size, self.n+self.m))\n",
        "    batch_out = np.empty((self.batch_size, self.n))\n",
        "    for i in range(self.batch_size):\n",
        "      batch_in[i] = self.getRandomInput()\n",
        "      batch_out[i] = self.dyn.run(batch_in[i].reshape(-1,1), self.dt).elements.flatten()\n",
        "    return batch_in, batch_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4SMzucDAkn5",
        "colab_type": "code",
        "outputId": "b654a3f0-08c5-434a-f830-c209c53bf187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "def testGen():\n",
        "  data_gen = DataGenerator(10,4,dt=0.01,batch_size=2)\n",
        "  ran = data_gen.getRandomInput()\n",
        "  print('rand: ', ran)\n",
        "\n",
        "  x, truth = data_gen.getBatch()\n",
        "  print('x: \\n', x)\n",
        "  print('truth: \\n', truth)\n",
        "\n",
        "  dyn = Dynamics()\n",
        "  for i, state in enumerate(x):\n",
        "    state = state.reshape(-1,1)\n",
        "    out = dyn.run(state, 0.01).elements.flatten()\n",
        "    error = out - truth[i]\n",
        "    norm = np.sqrt(error @ error)\n",
        "    print('norm: ', norm)\n",
        "\n",
        "testGen()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rand:  [ 2.13414923e+02 -1.82855143e+01 -1.42148705e+02  9.23423089e-01\n",
            " -1.16868690e-01  4.58987953e-02 -3.62663492e-01 -7.38148271e+00\n",
            " -8.31359410e+00  7.43511310e+00  4.41216117e-01  1.11084338e+00\n",
            " -4.52179099e+00 -2.56110851e-01]\n",
            "x: \n",
            " [[ 7.87187309e+01  1.78633755e+02 -1.21301048e+02  8.19239931e-01\n",
            "  -1.79401403e-01 -4.10309857e-01 -3.58199517e-01  9.05780015e+00\n",
            "   6.21664465e-01  7.23687671e+00  4.70058091e-01 -2.52360175e+00\n",
            "  -5.30594109e+00  5.18037233e+00]\n",
            " [ 2.22213428e+02  2.77736730e+01 -2.87663212e+02  5.07125555e-01\n",
            "  -5.32634750e-01 -5.19049883e-01 -4.35558392e-01  5.81242695e+00\n",
            "   4.16890686e+00 -9.41430763e+00  7.01144949e-01  6.16444134e+00\n",
            "  -1.39895478e+00  3.35849562e+00]]\n",
            "truth: \n",
            " [[ 7.87210294e+01  1.78640415e+02 -1.21185006e+02  8.14741612e-01\n",
            "  -2.09723929e-01 -4.22559587e-01 -3.37128129e-01  9.51384702e+00\n",
            "  -3.87694535e-02  6.70872992e+00]\n",
            " [ 2.22265559e+02  2.76882872e+01 -2.87598782e+02  5.26896951e-01\n",
            "  -5.28426518e-01 -5.26743616e-01 -4.07045675e-01  5.89510850e+00\n",
            "   3.36330287e+00 -9.86723134e+00]]\n",
            "norm:  0.0\n",
            "norm:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XvwSOVc3-Sy",
        "colab_type": "code",
        "outputId": "bf9ec3de-c834-4d7d-b377-1c1cfdf46d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "def testLinearSize():\n",
        "  inputs = 14\n",
        "  outputs = 10\n",
        "  batch = 1\n",
        "  x_test = torch.zeros(batch,inputs)\n",
        "  up = nn.Linear(inputs, 50)\n",
        "  up_test = up(x_test)\n",
        "  print('up: ', up_test.size())\n",
        "\n",
        "  down = nn.Linear(50, outputs)\n",
        "  down_test = down(up_test)\n",
        "  print('down: ', down_test.size())\n",
        "\n",
        "testLinearSize()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "up:  torch.Size([1, 50])\n",
            "down:  torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9EXL6hvwr08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "  def __init__(self, dim_in, dim_out, skip=False):\n",
        "    super(ResBlock, self).__init__()\n",
        "    self.skip = skip\n",
        "    self.activation = nn.ReLU()\n",
        "    self.layer1 = nn.Linear(dim_in, dim_in)\n",
        "    self.layer2 = nn.Linear(dim_in, dim_in)\n",
        "    self.layer3 = nn.Linear(dim_in, dim_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out1 = self.activation(self.layer1(x))\n",
        "    out2 = self.layer2(out1)\n",
        "    skip = self.activation(out2 + out1)\n",
        "    out3 = self.activation(self.layer3(skip))\n",
        "    if self.skip:\n",
        "      return skip, out3\n",
        "    else:\n",
        "      return out3\n",
        "\n",
        "class DynamicsNN(nn.Module):\n",
        "  def __init__(self, num_states, num_inputs):\n",
        "    super(DynamicsNN, self).__init__()\n",
        "    self.up1 = nn.Linear(num_states+num_inputs, 50)\n",
        "    self.up2 = ResBlock(50,  100, skip=True)\n",
        "    self.up3 = ResBlock(100, 200, skip=True)\n",
        "    # self.up4 = ResBlock(200, 400, skip=True)\n",
        "    self.dn1 = ResBlock(200, 100)\n",
        "    self.dn2 = ResBlock(100, 50)\n",
        "    self.dn3 = ResBlock(50,  num_states)\n",
        "    # self.dn4 = ResBlock(50, num_states)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # set_trace()\n",
        "    up1 = self.up1(x)\n",
        "    skip1, up2 = self.up2(up1)\n",
        "    skip2, up3 = self.up3(up2)\n",
        "    down1 = self.dn1(up3)\n",
        "    down2 = self.dn2(skip2 + down1)\n",
        "    down3 = self.dn3(skip1 + down2)\n",
        "    p = down3[:,:3]\n",
        "    q = down3[:,3:7]\n",
        "    q1 = q / torch.norm(q, dim=1, keepdim=True)\n",
        "    # mask = (q[:,0] < 0).squeeze()\n",
        "    v = down3[:,7:]\n",
        "\n",
        "    out = torch.cat((p,q1,v), dim=1)\n",
        "\n",
        "    # out[:,3:7] /= torch.norm(out[:,3:7], dim=1, keepdim=True)\n",
        "    # mask = (out[:,3] < 0).squeeze()\n",
        "    # out[mask,3:7] *= -1\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0Mc_4YUWlt",
        "colab_type": "code",
        "outputId": "360a80e3-e4d7-4011-d37e-1ea8fd6314b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "def testNet():\n",
        "  n = 10\n",
        "  m = 4\n",
        "  x_test = torch.randn(2,n+m)\n",
        "  print('x_test: ', x_test)\n",
        "  net = DynamicsNN(n,m)\n",
        "  test = net(x_test)\n",
        "  print('shape: ', test.shape)\n",
        "  print('output: ', test)\n",
        "\n",
        "testNet()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test:  tensor([[ 2.7724,  2.6250, -0.2032,  2.9163, -0.2386, -0.5875,  1.0248,  0.1967,\n",
            "         -2.8995, -1.0132,  2.2326,  1.0678,  0.3425,  0.5711],\n",
            "        [ 0.7462,  0.8280, -1.7734,  1.0156, -0.1763, -0.2437,  0.0475, -0.0535,\n",
            "          1.7576, -0.3544, -0.1903,  0.5649,  0.4224,  1.9021]])\n",
            "shape:  torch.Size([2, 10])\n",
            "output:  tensor([[0.0000, 0.0469, 0.0000, 0.4794, 0.0000, 0.8776, 0.0000, 0.0000, 0.0000,\n",
            "         0.0929],\n",
            "        [0.0000, 0.0000, 0.0000, 0.6807, 0.0000, 0.7326, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000]], grad_fn=<CatBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ_yf9ICTpBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd7e067e-028d-4c90-be54-4aed066bf7e0"
      },
      "source": [
        "def train(save_model):\n",
        "  n = 10\n",
        "  m = 4\n",
        "  dt = 0.01\n",
        "  model = DynamicsNN(n, m).cuda()\n",
        "\n",
        "  lr = 1e-2\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  epochs = 100\n",
        "  batch_size = 1000\n",
        "  data_gen = DataGenerator(n, m, dt, batch_size)\n",
        "\n",
        "  save_every = 10\n",
        "  decay_every = 1000\n",
        "  # validate_every = 1000\n",
        "\n",
        "  epoch_hist = []\n",
        "  loss_hist = []\n",
        "  # vals = []\n",
        "\n",
        "  num_nans = 0\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    xu_t, x_tp1 = data_gen.getBatch()\n",
        "    in_var = Variable(torch.from_numpy(xu_t).float(), requires_grad=True).cuda()\n",
        "    out_truth = Variable(torch.from_numpy(x_tp1).float(), requires_grad=False).cuda()\n",
        "\n",
        "    out_pred = model(in_var)\n",
        "\n",
        "    # set_trace()\n",
        "    loss = loss_fn(out_pred, out_truth)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if np.isnan(loss.item()):\n",
        "      num_nans += 1\n",
        "\n",
        "    # if epoch % validate_every == 0:\n",
        "      # validate()\n",
        "\n",
        "    if epoch % save_every == 0:\n",
        "      epoch_hist.append(epoch)\n",
        "      loss_hist.append(loss.item() / batch_size)\n",
        "      if save_model:\n",
        "        torch.save(model, 'learned_quadrotor_model.pt')\n",
        "    \n",
        "    if epoch % decay_every == 0:\n",
        "      lr *= 0.9\n",
        "      for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "  \n",
        "  fig, ax = plt.subplots()\n",
        "  train_losses, = ax.plot(epoch_hist, loss_hist, 'b', label='train')\n",
        "  ax.set_xlabel('Epoch')\n",
        "  ax.set_ylabel('Loss')\n",
        "  ax.legend()\n",
        "  # plt.pause(0.0001)\n",
        "  print('\\nepoch history: ', epoch_hist)\n",
        "  print('\\nloss history: ', loss_hist)\n",
        "  print('Nans: ', num_nans)\n",
        "  plt.show()\n",
        "\n",
        "train(save_model=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/100 [00:00<01:05,  1.52it/s]\u001b[A\n",
            "  2%|▏         | 2/100 [00:01<01:04,  1.52it/s]\u001b[A\n",
            "  3%|▎         | 3/100 [00:02<01:05,  1.49it/s]\u001b[A\n",
            "  4%|▍         | 4/100 [00:02<01:04,  1.49it/s]\u001b[A\n",
            "  5%|▌         | 5/100 [00:03<01:04,  1.48it/s]\u001b[A\n",
            "  6%|▌         | 6/100 [00:04<01:04,  1.46it/s]\u001b[A\n",
            "  7%|▋         | 7/100 [00:04<01:03,  1.47it/s]\u001b[A\n",
            "  8%|▊         | 8/100 [00:05<01:03,  1.46it/s]\u001b[A\n",
            "  9%|▉         | 9/100 [00:06<01:02,  1.46it/s]\u001b[A\n",
            " 10%|█         | 10/100 [00:06<01:00,  1.48it/s]\u001b[A\n",
            " 11%|█         | 11/100 [00:07<01:00,  1.47it/s]\u001b[A\n",
            " 12%|█▏        | 12/100 [00:08<01:01,  1.44it/s]\u001b[A\n",
            " 13%|█▎        | 13/100 [00:08<00:58,  1.49it/s]\u001b[A\n",
            " 14%|█▍        | 14/100 [00:09<00:55,  1.54it/s]\u001b[A\n",
            " 15%|█▌        | 15/100 [00:10<00:55,  1.53it/s]\u001b[A\n",
            " 16%|█▌        | 16/100 [00:10<00:54,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 17/100 [00:11<00:54,  1.51it/s]\u001b[A\n",
            " 18%|█▊        | 18/100 [00:12<00:55,  1.48it/s]\u001b[A\n",
            " 19%|█▉        | 19/100 [00:12<00:53,  1.51it/s]\u001b[A\n",
            " 20%|██        | 20/100 [00:13<00:52,  1.53it/s]\u001b[A\n",
            " 21%|██        | 21/100 [00:14<00:52,  1.51it/s]\u001b[A\n",
            " 22%|██▏       | 22/100 [00:14<00:50,  1.54it/s]\u001b[A\n",
            " 23%|██▎       | 23/100 [00:15<00:49,  1.54it/s]\u001b[A\n",
            " 24%|██▍       | 24/100 [00:15<00:49,  1.55it/s]\u001b[A\n",
            " 25%|██▌       | 25/100 [00:16<00:48,  1.56it/s]\u001b[A\n",
            " 26%|██▌       | 26/100 [00:17<00:46,  1.58it/s]\u001b[A\n",
            " 27%|██▋       | 27/100 [00:17<00:48,  1.52it/s]\u001b[A\n",
            " 28%|██▊       | 28/100 [00:18<00:47,  1.52it/s]\u001b[A\n",
            " 29%|██▉       | 29/100 [00:19<00:46,  1.54it/s]\u001b[A\n",
            " 30%|███       | 30/100 [00:19<00:44,  1.58it/s]\u001b[A\n",
            " 31%|███       | 31/100 [00:20<00:44,  1.55it/s]\u001b[A\n",
            " 32%|███▏      | 32/100 [00:21<00:44,  1.53it/s]\u001b[A\n",
            " 33%|███▎      | 33/100 [00:21<00:44,  1.50it/s]\u001b[A\n",
            " 34%|███▍      | 34/100 [00:22<00:44,  1.47it/s]\u001b[A\n",
            " 35%|███▌      | 35/100 [00:23<00:44,  1.47it/s]\u001b[A\n",
            " 36%|███▌      | 36/100 [00:23<00:42,  1.49it/s]\u001b[A\n",
            " 37%|███▋      | 37/100 [00:24<00:41,  1.54it/s]\u001b[A\n",
            " 38%|███▊      | 38/100 [00:25<00:41,  1.50it/s]\u001b[A\n",
            " 39%|███▉      | 39/100 [00:25<00:40,  1.51it/s]\u001b[A\n",
            " 40%|████      | 40/100 [00:26<00:39,  1.51it/s]\u001b[A\n",
            " 41%|████      | 41/100 [00:27<00:39,  1.51it/s]\u001b[A\n",
            " 42%|████▏     | 42/100 [00:27<00:37,  1.55it/s]\u001b[A\n",
            " 43%|████▎     | 43/100 [00:28<00:36,  1.57it/s]\u001b[A\n",
            " 44%|████▍     | 44/100 [00:29<00:35,  1.56it/s]\u001b[A\n",
            " 45%|████▌     | 45/100 [00:29<00:36,  1.50it/s]\u001b[A\n",
            " 46%|████▌     | 46/100 [00:30<00:36,  1.48it/s]\u001b[A\n",
            " 47%|████▋     | 47/100 [00:31<00:34,  1.53it/s]\u001b[A\n",
            " 48%|████▊     | 48/100 [00:31<00:33,  1.55it/s]\u001b[A\n",
            " 49%|████▉     | 49/100 [00:32<00:33,  1.54it/s]\u001b[A\n",
            " 50%|█████     | 50/100 [00:32<00:31,  1.58it/s]\u001b[A\n",
            " 51%|█████     | 51/100 [00:33<00:31,  1.58it/s]\u001b[A\n",
            " 52%|█████▏    | 52/100 [00:34<00:30,  1.58it/s]\u001b[A\n",
            " 53%|█████▎    | 53/100 [00:34<00:29,  1.58it/s]\u001b[A\n",
            " 54%|█████▍    | 54/100 [00:35<00:28,  1.59it/s]\u001b[A\n",
            " 55%|█████▌    | 55/100 [00:36<00:27,  1.62it/s]\u001b[A\n",
            " 56%|█████▌    | 56/100 [00:36<00:27,  1.61it/s]\u001b[A\n",
            " 57%|█████▋    | 57/100 [00:37<00:26,  1.62it/s]\u001b[A\n",
            " 58%|█████▊    | 58/100 [00:37<00:25,  1.64it/s]\u001b[A\n",
            " 59%|█████▉    | 59/100 [00:38<00:25,  1.59it/s]\u001b[A\n",
            " 60%|██████    | 60/100 [00:39<00:24,  1.60it/s]\u001b[A\n",
            " 61%|██████    | 61/100 [00:39<00:25,  1.54it/s]\u001b[A\n",
            " 62%|██████▏   | 62/100 [00:40<00:25,  1.51it/s]\u001b[A\n",
            " 63%|██████▎   | 63/100 [00:41<00:24,  1.48it/s]\u001b[A\n",
            " 64%|██████▍   | 64/100 [00:42<00:24,  1.46it/s]\u001b[A\n",
            " 65%|██████▌   | 65/100 [00:42<00:23,  1.49it/s]\u001b[A\n",
            " 66%|██████▌   | 66/100 [00:43<00:22,  1.49it/s]\u001b[A\n",
            " 67%|██████▋   | 67/100 [00:43<00:22,  1.49it/s]\u001b[A\n",
            " 68%|██████▊   | 68/100 [00:44<00:20,  1.52it/s]\u001b[A\n",
            " 69%|██████▉   | 69/100 [00:45<00:20,  1.53it/s]\u001b[A\n",
            " 70%|███████   | 70/100 [00:45<00:19,  1.58it/s]\u001b[A\n",
            " 71%|███████   | 71/100 [00:46<00:18,  1.61it/s]\u001b[A\n",
            " 72%|███████▏  | 72/100 [00:47<00:17,  1.59it/s]\u001b[A\n",
            " 73%|███████▎  | 73/100 [00:47<00:17,  1.59it/s]\u001b[A\n",
            " 74%|███████▍  | 74/100 [00:48<00:16,  1.56it/s]\u001b[A\n",
            " 75%|███████▌  | 75/100 [00:48<00:15,  1.58it/s]\u001b[A\n",
            " 76%|███████▌  | 76/100 [00:49<00:15,  1.60it/s]\u001b[A\n",
            " 77%|███████▋  | 77/100 [00:50<00:14,  1.57it/s]\u001b[A\n",
            " 78%|███████▊  | 78/100 [00:50<00:13,  1.59it/s]\u001b[A\n",
            " 79%|███████▉  | 79/100 [00:51<00:13,  1.58it/s]\u001b[A\n",
            " 80%|████████  | 80/100 [00:52<00:12,  1.59it/s]\u001b[A\n",
            " 81%|████████  | 81/100 [00:52<00:12,  1.52it/s]\u001b[A\n",
            " 82%|████████▏ | 82/100 [00:53<00:11,  1.53it/s]\u001b[A\n",
            " 83%|████████▎ | 83/100 [00:54<00:10,  1.57it/s]\u001b[A\n",
            " 84%|████████▍ | 84/100 [00:54<00:10,  1.59it/s]\u001b[A\n",
            " 85%|████████▌ | 85/100 [00:55<00:09,  1.55it/s]\u001b[A\n",
            " 86%|████████▌ | 86/100 [00:56<00:09,  1.50it/s]\u001b[A\n",
            " 87%|████████▋ | 87/100 [00:56<00:08,  1.54it/s]\u001b[A\n",
            " 88%|████████▊ | 88/100 [00:57<00:07,  1.56it/s]\u001b[A\n",
            " 89%|████████▉ | 89/100 [00:58<00:07,  1.50it/s]\u001b[A\n",
            " 90%|█████████ | 90/100 [00:58<00:06,  1.50it/s]\u001b[A\n",
            " 91%|█████████ | 91/100 [00:59<00:05,  1.51it/s]\u001b[A\n",
            " 92%|█████████▏| 92/100 [01:00<00:05,  1.48it/s]\u001b[A\n",
            " 93%|█████████▎| 93/100 [01:00<00:04,  1.49it/s]\u001b[A\n",
            " 94%|█████████▍| 94/100 [01:01<00:03,  1.51it/s]\u001b[A\n",
            " 95%|█████████▌| 95/100 [01:02<00:03,  1.49it/s]\u001b[A\n",
            " 96%|█████████▌| 96/100 [01:02<00:02,  1.53it/s]\u001b[A\n",
            " 97%|█████████▋| 97/100 [01:03<00:01,  1.53it/s]\u001b[A\n",
            " 98%|█████████▊| 98/100 [01:03<00:01,  1.58it/s]\u001b[A\n",
            " 99%|█████████▉| 99/100 [01:04<00:00,  1.59it/s]\u001b[A\n",
            "100%|██████████| 100/100 [01:05<00:00,  1.60it/s]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch history:  [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
            "\n",
            "loss history:  [9.1387763671875, 8.4961376953125, 7.643990234375, 7.41815283203125, 6.7194638671875, 6.05037939453125, 6.2683408203125, 5.868318359375, 5.89025537109375, 6.0242998046875]\n",
            "Nans:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}